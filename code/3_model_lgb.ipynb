{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "from gensim.models.word2vec import Word2Vec \n",
    "import logging\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import time\n",
    "from datetime import datetime\n",
    "import IPython.display as ipd\n",
    "from collections import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/data/cch/weibo'\n",
    "VAR_PATH = 'var'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.4'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_weibo_with_repost = pickle.load(open('%s/df_all.pickle'%VAR_PATH, 'rb'))\n",
    "\n",
    "df_24h_feature_predict = pickle.load(open('%s/df_24h_feature_predict.pickle'%VAR_PATH, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     5,
     32
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19798468224654805 0.19798468224654805\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "评估函数传入的是1，2，3，4，5五个档位的值，注意从1开始\n",
    "\n",
    "'''\n",
    "\n",
    "def precision_score_hyr(predictions, ground_truths):\n",
    "    predictions, ground_truths = np.array(predictions)-1, np.array(ground_truths)-1\n",
    "    \n",
    "    score, total = 0, 0\n",
    "    for p_cnt, g_cnt in zip(predictions, ground_truths):\n",
    "        if g_cnt==0:\n",
    "            total += 1\n",
    "            if p_cnt == g_cnt:\n",
    "                score += 1\n",
    "        elif g_cnt==1:\n",
    "            total += 10\n",
    "            if p_cnt == g_cnt:\n",
    "                score += 10\n",
    "        elif  g_cnt==2:\n",
    "            total += 50\n",
    "            if p_cnt == g_cnt:\n",
    "                score += 50\n",
    "        elif  g_cnt==3:\n",
    "            total += 100\n",
    "            if p_cnt == g_cnt:\n",
    "                score += 100\n",
    "        elif  g_cnt==4:\n",
    "            total += 300\n",
    "            if p_cnt == g_cnt:\n",
    "                score += 300\n",
    "    return score/total\n",
    "\n",
    "def precision_score_cch(predictions, ground_truths):\n",
    "    \n",
    "    predictions, ground_truths = np.array(predictions)-1, np.array(ground_truths)-1\n",
    "    y_pred = predictions\n",
    "    y_true = ground_truths\n",
    "\n",
    "    w=[1,10,50,100,300]\n",
    "    n = len(y_true)\n",
    "    count_r = [0 for i in range(5)]\n",
    "    count = [0 for i in range(5)]\n",
    "    for i in range(n):\n",
    "        count[y_true[i]] += 1\n",
    "        if y_pred[i] == y_true[i]:\n",
    "            count_r[y_pred[i]] += 1\n",
    "    sum1 = sum(w[i]*count_r[i] for i in range(5))\n",
    "    sum2 = sum(w[i]*count[i] for i in range(5))\n",
    "    precision = sum1/sum2\n",
    "    return precision\n",
    "\n",
    "#随机数测试\n",
    "predictions   = [random.randint(1,5) for i in range(18000)]\n",
    "ground_truths = [random.randint(1,5) for i in range(18000)]\n",
    "# print(predictions, ground_truths)\n",
    "print(precision_score_hyr(predictions, ground_truths), precision_score_cch(predictions, ground_truths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangweilin/anaconda3/envs/hyr2/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_weibo_with_repost.index = df_weibo_with_repost['WeiboId']\n",
    "df_weibo_with_repost = pd.concat([df_weibo_with_repost, df_24h_feature_predict], 1)\n",
    "feature_names_24h = list(df_24h_feature_predict.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_feature_list = [\n",
    "    \n",
    "    #文本硬特征\n",
    "    'weibotext_len', \n",
    "    '转发&点赞', '疫情', '特朗普|总统', '视频|链接', '粉|饭', '中国&金牌', '台湾',\n",
    "    '历史', '发展|经济', '推荐', '东京&奥运',    \n",
    "    \n",
    "    #文本stacking\n",
    "#     'text_stacking_0','text_stacking_1','text_stacking_2','text_stacking_3', 'text_stacking_4',\n",
    "   \n",
    "    #性别\n",
    "    'Gender', \n",
    "    \n",
    "    #用户粉丝，关注数\n",
    "    'follow_mean', 'follow_median', 'follow_max', 'follow_min', 'follower_mean',\n",
    "    'follower_median', 'follower_max', 'follower_min',\n",
    "\n",
    "    #微博发布时间\n",
    "    'post_day', 'post_weekday', 'post_month', 'post_hour', 'post_minute', 'post_year',\n",
    "    \n",
    "    #user id target encode\n",
    "#     'target_encode_0', 'target_encode_1', 'target_encode_2', 'target_encode_3', 'target_encode_4',\n",
    "#     'target_encode_cnt', \n",
    "    \n",
    "    #转发特征(微博维度)\n",
    "     'repost_weibo_cnt_15_30_mins', 'repost_weibo_cnt_15_mins','repost_weibo_cnt_30_45_mins','repost_weibo_cnt_30_mins',\n",
    "     'repost_weibo_cnt_45_60_mins','repost_weibo_cnt_45_mins','repost_weibo_cnt_60_mins',\n",
    "     'repost_weibo_follow_max_max',\n",
    "     'repost_weibo_follow_max_mean','repost_weibo_follow_max_min','repost_weibo_follow_max_sum','repost_weibo_follow_mean_max',\n",
    "     'repost_weibo_follow_mean_mean','repost_weibo_follow_mean_min','repost_weibo_follow_mean_sum','repost_weibo_follow_median_max',\n",
    "     'repost_weibo_follow_median_mean','repost_weibo_follow_median_min','repost_weibo_follow_median_sum',\n",
    "     'repost_weibo_follow_min_max', 'repost_weibo_follow_min_mean','repost_weibo_follow_min_min','repost_weibo_follow_min_sum',\n",
    "     'repost_weibo_follower_max_max','repost_weibo_follower_max_mean','repost_weibo_follower_max_min',\n",
    "     'repost_weibo_follower_max_sum','repost_weibo_follower_mean_max','repost_weibo_follower_mean_mean',\n",
    "     'repost_weibo_follower_mean_min','repost_weibo_follower_mean_sum','repost_weibo_follower_median_max',\n",
    "     'repost_weibo_follower_median_mean','repost_weibo_follower_median_min','repost_weibo_follower_median_sum',\n",
    "     'repost_weibo_follower_min_max','repost_weibo_follower_min_mean','repost_weibo_follower_min_min',\n",
    "     'repost_weibo_follower_min_sum','repost_weibo_pass_time_max','repost_weibo_pass_time_mean','repost_weibo_pass_time_median',\n",
    "     'repost_weibo_pass_time_min', 'repost_weibo_Verified', 'repost_weibo_Gender',\n",
    "    \n",
    "    #水军\n",
    "     'repost_weibo_unique_repost_userid',\n",
    "     'repost_weibo_repeat_repost_cnt',\n",
    "     'repost_weibo_max_user_repost',\n",
    "     'repost_weibo_other_cnt_max',\n",
    "     'repost_weibo_other_cnt_min',\n",
    "     'repost_weibo_other_cnt_mean',\n",
    "     'repost_weibo_other_cnt_std',\n",
    "     'repost_weibo_other_cnt_0',\n",
    "     'repost_weibo_text_len_max',\n",
    "     'repost_weibo_text_len_min',\n",
    "     'repost_weibo_text_len_mean',\n",
    "     'repost_weibo_text_len_std',\n",
    "\n",
    "    #转发特征(用户维度)    \n",
    "     'repost_userid_cnt_15_30_mins','repost_userid_cnt_15_mins','repost_userid_cnt_30_45_mins','repost_userid_cnt_30_mins',\n",
    "     'repost_userid_cnt_45_60_mins','repost_userid_cnt_45_mins','repost_userid_cnt_60_mins',\n",
    "    'repost_userid_follow_max_max',\n",
    "     'repost_userid_follow_max_mean','repost_userid_follow_max_min','repost_userid_follow_max_sum',\n",
    "       'repost_userid_follow_mean_max',\n",
    "     'repost_userid_follow_mean_mean','repost_userid_follow_mean_min','repost_userid_follow_mean_sum',\n",
    "     'repost_userid_follow_median_max','repost_userid_follow_median_mean','repost_userid_follow_median_min',\n",
    "     'repost_userid_follow_median_sum','repost_userid_follow_min_max','repost_userid_follow_min_mean',\n",
    "     'repost_userid_follow_min_min','repost_userid_follow_min_sum','repost_userid_follower_max_max',\n",
    "     'repost_userid_follower_max_mean','repost_userid_follower_max_min','repost_userid_follower_max_sum',\n",
    "     'repost_userid_follower_mean_max','repost_userid_follower_mean_mean','repost_userid_follower_mean_min',\n",
    "     'repost_userid_follower_mean_sum','repost_userid_follower_median_max','repost_userid_follower_median_mean',\n",
    "     'repost_userid_follower_median_min','repost_userid_follower_median_sum','repost_userid_follower_min_max',\n",
    "     'repost_userid_follower_min_mean','repost_userid_follower_min_min','repost_userid_follower_min_sum',\n",
    "     'repost_userid_pass_time_max','repost_userid_pass_time_mean','repost_userid_pass_time_median',\n",
    "     'repost_userid_pass_time_min', 'repost_userid_Verified', 'repost_userid_Gender',\n",
    "        \n",
    "     'repost_userid_unique_repost_userid',\n",
    "     'repost_userid_repeat_repost_cnt',\n",
    "     'repost_userid_max_user_repost',\n",
    "     'repost_userid_other_cnt_max',\n",
    "     'repost_userid_other_cnt_min',\n",
    "     'repost_userid_other_cnt_mean',\n",
    "     'repost_userid_other_cnt_std',\n",
    "     'repost_userid_other_cnt_0',\n",
    "     'repost_userid_text_len_max',\n",
    "     'repost_userid_text_len_min',\n",
    "     'repost_userid_text_len_mean',\n",
    "     'repost_userid_text_len_std',\n",
    "    \n",
    "    #交叉特征\n",
    "    'userid_idx', \n",
    "    'cross_userid_idx_post_hour',\n",
    "    'cross_userid_idx_post_weekday', \n",
    "    'cross_repost_1h_cnt_idx_post_hour', 'cross_repost_1h_cnt_idx_post_weekday',\n",
    "    \n",
    "    \n",
    "    #交叉特征 24h转发特征 target encode\n",
    "#     'target_encode_24h_10_reposet_cnt',\n",
    "#        'target_encode_24h_11_reposet_cnt', 'target_encode_24h_12_reposet_cnt',\n",
    "#        'target_encode_24h_13_reposet_cnt', 'target_encode_24h_14_reposet_cnt',\n",
    "#        'target_encode_24h_15_reposet_cnt', 'target_encode_24h_16_reposet_cnt',\n",
    "#        'target_encode_24h_17_reposet_cnt', 'target_encode_24h_18_reposet_cnt',\n",
    "#        'target_encode_24h_19_reposet_cnt', 'target_encode_24h_20_reposet_cnt',\n",
    "#        'target_encode_24h_21_reposet_cnt', 'target_encode_24h_22_reposet_cnt',\n",
    "#        'target_encode_24h_23_reposet_cnt', 'target_encode_24h_24_reposet_cnt',\n",
    "#        'target_encode_24h_2_reposet_cnt', 'target_encode_24h_3_reposet_cnt',\n",
    "#        'target_encode_24h_4_reposet_cnt', 'target_encode_24h_5_reposet_cnt',\n",
    "#        'target_encode_24h_6_reposet_cnt', 'target_encode_24h_7_reposet_cnt',\n",
    "#        'target_encode_24h_8_reposet_cnt', 'target_encode_24h_9_reposet_cnt'\n",
    "\n",
    "]\n",
    "\n",
    "hidden_feature_list = [\n",
    "    'weibotext_wv_embed', 'weibotext_tfidf',#微博内容词向量/tfidf+svd降维\n",
    "    'user_intro_wv_embed', 'user_intro_tfidf'#用户个性签名词向量/tfidf+svd降维\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18000, 129), (18000,), (2329, 129))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_train_test_from_df(df, fix_feature_list, hidden_feature_list):\n",
    "    df_train = df.query('type==\"train\"')\n",
    "    df_test = df.query('type==\"test\"')\n",
    "    train_x_fix, train_y, test_x_fix = \\\n",
    "        np.array(df_train[fix_feature_list]), np.array(df_train['label']), np.array(df_test[fix_feature_list])\n",
    "    \n",
    "    train_x_list = [train_x_fix]\n",
    "    test_x_list = [test_x_fix]\n",
    "    \n",
    "    feature_name_list = fix_feature_list[:]\n",
    "    for f in hidden_feature_list:\n",
    "        hidden_train = np.array(list(df_train[f]))\n",
    "        hidden_test = np.array(list(df_test[f]))\n",
    "        train_x_list.append(hidden_train)\n",
    "        test_x_list.append(hidden_test)\n",
    "        feature_name_list += ['%s_%d'%(f,i) for i in range(hidden_train.shape[1])]\n",
    "        \n",
    "    return np.concatenate(train_x_list,1), train_y, np.concatenate(test_x_list,1), feature_name_list,\\\n",
    "list(df_train['WeiboId']), list(df_test['WeiboId'])\n",
    "    \n",
    "train_x, train_y, test_x, feature_name_list, train_weibo_ids, test_weibo_ids = \\\n",
    "get_train_test_from_df(df_weibo_with_repost, fix_feature_list, hidden_feature_list)\n",
    "\n",
    "train_x.shape, train_y.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangweilin/anaconda3/envs/hyr2/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/huangweilin/anaconda3/envs/hyr2/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.30818\n",
      "[200]\ttraining's multi_error: 0.277379\n",
      "[300]\ttraining's multi_error: 0.255147\n",
      "[400]\ttraining's multi_error: 0.239506\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.239506\n",
      "0.7074089068825911\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.297513\n",
      "[200]\ttraining's multi_error: 0.270007\n",
      "[300]\ttraining's multi_error: 0.249186\n",
      "[400]\ttraining's multi_error: 0.2316\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[391]\ttraining's multi_error: 0.230507\n",
      "0.6834577114427861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.295304\n",
      "[200]\ttraining's multi_error: 0.2686\n",
      "[300]\ttraining's multi_error: 0.248043\n",
      "[400]\ttraining's multi_error: 0.23218\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.23218\n",
      "0.6621989358677551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.311854\n",
      "[200]\ttraining's multi_error: 0.284429\n",
      "[300]\ttraining's multi_error: 0.263582\n",
      "[400]\ttraining's multi_error: 0.243936\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.243936\n",
      "0.6864195248220394\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.306118\n",
      "[200]\ttraining's multi_error: 0.27618\n",
      "[300]\ttraining's multi_error: 0.254698\n",
      "[400]\ttraining's multi_error: 0.230207\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[395]\ttraining's multi_error: 0.229672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 13:57:56,445 - INFO - time:1 SEED:33 train score:0.764839 val score:0.680526 cost:49.376096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6632950272732087\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.301708\n",
      "[200]\ttraining's multi_error: 0.272767\n",
      "[300]\ttraining's multi_error: 0.250932\n",
      "[400]\ttraining's multi_error: 0.233188\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\ttraining's multi_error: 0.232397\n",
      "0.6615703833133122\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.31552\n",
      "[200]\ttraining's multi_error: 0.28072\n",
      "[300]\ttraining's multi_error: 0.255649\n",
      "[400]\ttraining's multi_error: 0.234704\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\ttraining's multi_error: 0.234211\n",
      "0.6939144059806929\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.318689\n",
      "[200]\ttraining's multi_error: 0.278857\n",
      "[300]\ttraining's multi_error: 0.246412\n",
      "[400]\ttraining's multi_error: 0.234289\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.234289\n",
      "0.6972660174406923\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.303334\n",
      "[200]\ttraining's multi_error: 0.272371\n",
      "[300]\ttraining's multi_error: 0.254615\n",
      "[400]\ttraining's multi_error: 0.23158\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.23158\n",
      "0.6790296685060511\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.298971\n",
      "[200]\ttraining's multi_error: 0.274238\n",
      "[300]\ttraining's multi_error: 0.253843\n",
      "[400]\ttraining's multi_error: 0.228912\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.228912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 13:58:51,959 - INFO - time:2 SEED:948 train score:0.767722 val score:0.684561 cost:104.890079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6903816995187554\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.29615\n",
      "[200]\ttraining's multi_error: 0.270138\n",
      "[300]\ttraining's multi_error: 0.250686\n",
      "[400]\ttraining's multi_error: 0.234385\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[398]\ttraining's multi_error: 0.234142\n",
      "0.6623799961488736\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.299728\n",
      "[200]\ttraining's multi_error: 0.273836\n",
      "[300]\ttraining's multi_error: 0.243954\n",
      "[400]\ttraining's multi_error: 0.226079\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[377]\ttraining's multi_error: 0.225364\n",
      "0.6376260740901625\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.307378\n",
      "[200]\ttraining's multi_error: 0.274294\n",
      "[300]\ttraining's multi_error: 0.256683\n",
      "[400]\ttraining's multi_error: 0.236659\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.236659\n",
      "0.7079734265930702\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.31238\n",
      "[200]\ttraining's multi_error: 0.284361\n",
      "[300]\ttraining's multi_error: 0.262663\n",
      "[400]\ttraining's multi_error: 0.242895\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[395]\ttraining's multi_error: 0.242168\n",
      "0.7080788648013532\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.30809\n",
      "[200]\ttraining's multi_error: 0.271086\n",
      "[300]\ttraining's multi_error: 0.251569\n",
      "[400]\ttraining's multi_error: 0.234404\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.234404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 13:59:50,892 - INFO - time:3 SEED:87 train score:0.765453 val score:0.681024 cost:163.823376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687913409500902\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.302028\n",
      "[200]\ttraining's multi_error: 0.271122\n",
      "[300]\ttraining's multi_error: 0.251857\n",
      "[400]\ttraining's multi_error: 0.233418\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\ttraining's multi_error: 0.233316\n",
      "0.664112322567373\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.309519\n",
      "[200]\ttraining's multi_error: 0.276272\n",
      "[300]\ttraining's multi_error: 0.253105\n",
      "[400]\ttraining's multi_error: 0.23108\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.23108\n",
      "0.6704092873485298\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.303473\n",
      "[200]\ttraining's multi_error: 0.272383\n",
      "[300]\ttraining's multi_error: 0.25014\n",
      "[400]\ttraining's multi_error: 0.234295\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[398]\ttraining's multi_error: 0.234265\n",
      "0.6920518064076346\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.307736\n",
      "[200]\ttraining's multi_error: 0.276548\n",
      "[300]\ttraining's multi_error: 0.255206\n",
      "[400]\ttraining's multi_error: 0.234913\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.234913\n",
      "0.7043199709494599\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.304907\n",
      "[200]\ttraining's multi_error: 0.276211\n",
      "[300]\ttraining's multi_error: 0.254268\n",
      "[400]\ttraining's multi_error: 0.232227\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.232227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 14:00:43,250 - INFO - time:4 SEED:454 train score:0.766840 val score:0.682442 cost:216.181293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6809004221571827\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.297544\n",
      "[200]\ttraining's multi_error: 0.27044\n",
      "[300]\ttraining's multi_error: 0.248505\n",
      "[400]\ttraining's multi_error: 0.230128\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.230128\n",
      "0.6412714083946961\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.306418\n",
      "[200]\ttraining's multi_error: 0.27899\n",
      "[300]\ttraining's multi_error: 0.255724\n",
      "[400]\ttraining's multi_error: 0.228399\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.228399\n",
      "0.6825425722608112\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.301423\n",
      "[200]\ttraining's multi_error: 0.27498\n",
      "[300]\ttraining's multi_error: 0.249317\n",
      "[400]\ttraining's multi_error: 0.231482\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.231482\n",
      "0.6799724055838112\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.312697\n",
      "[200]\ttraining's multi_error: 0.282739\n",
      "[300]\ttraining's multi_error: 0.26231\n",
      "[400]\ttraining's multi_error: 0.243343\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[394]\ttraining's multi_error: 0.2416\n",
      "0.7239938448450577\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.30538\n",
      "[200]\ttraining's multi_error: 0.273927\n",
      "[300]\ttraining's multi_error: 0.251781\n",
      "[400]\ttraining's multi_error: 0.231666\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.231666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 14:01:40,992 - INFO - time:5 SEED:257 train score:0.767345 val score:0.685837 cost:273.923052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6974235190568906\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.308066\n",
      "[200]\ttraining's multi_error: 0.274536\n",
      "[300]\ttraining's multi_error: 0.252159\n",
      "[400]\ttraining's multi_error: 0.23017\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\ttraining's multi_error: 0.230121\n",
      "0.7000476802820361\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.298082\n",
      "[200]\ttraining's multi_error: 0.271633\n",
      "[300]\ttraining's multi_error: 0.252816\n",
      "[400]\ttraining's multi_error: 0.230897\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.230897\n",
      "0.6876924291466014\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.304364\n",
      "[200]\ttraining's multi_error: 0.27024\n",
      "[300]\ttraining's multi_error: 0.249067\n",
      "[400]\ttraining's multi_error: 0.231179\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\ttraining's multi_error: 0.230855\n",
      "0.6569679031119318\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.307053\n",
      "[200]\ttraining's multi_error: 0.2726\n",
      "[300]\ttraining's multi_error: 0.250076\n",
      "[400]\ttraining's multi_error: 0.229446\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.229446\n",
      "0.6892367334475114\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.308149\n",
      "[200]\ttraining's multi_error: 0.27864\n",
      "[300]\ttraining's multi_error: 0.252823\n",
      "[400]\ttraining's multi_error: 0.233685\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\ttraining's multi_error: 0.23355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 14:02:45,459 - INFO - time:6 SEED:1062 train score:0.769026 val score:0.686073 cost:338.390155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6963896906172464\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.311334\n",
      "[200]\ttraining's multi_error: 0.271244\n",
      "[300]\ttraining's multi_error: 0.255282\n",
      "[400]\ttraining's multi_error: 0.231878\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[398]\ttraining's multi_error: 0.231704\n",
      "0.684656353709453\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.299784\n",
      "[200]\ttraining's multi_error: 0.270965\n",
      "[300]\ttraining's multi_error: 0.252609\n",
      "[400]\ttraining's multi_error: 0.236034\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[398]\ttraining's multi_error: 0.235843\n",
      "0.6659621756500634\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.309581\n",
      "[200]\ttraining's multi_error: 0.275614\n",
      "[300]\ttraining's multi_error: 0.253244\n",
      "[400]\ttraining's multi_error: 0.235826\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[398]\ttraining's multi_error: 0.235326\n",
      "0.6787781682861278\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.31146\n",
      "[200]\ttraining's multi_error: 0.280634\n",
      "[300]\ttraining's multi_error: 0.258792\n",
      "[400]\ttraining's multi_error: 0.23786\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.23786\n",
      "0.6901819430140749\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.300378\n",
      "[200]\ttraining's multi_error: 0.274226\n",
      "[300]\ttraining's multi_error: 0.252101\n",
      "[400]\ttraining's multi_error: 0.233591\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\ttraining's multi_error: 0.232702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 14:03:48,076 - INFO - time:7 SEED:374 train score:0.765313 val score:0.680762 cost:401.006908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6840175036465931\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.30198\n",
      "[200]\ttraining's multi_error: 0.269862\n",
      "[300]\ttraining's multi_error: 0.253492\n",
      "[400]\ttraining's multi_error: 0.232103\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\ttraining's multi_error: 0.231598\n",
      "0.6811199140593528\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.300437\n",
      "[200]\ttraining's multi_error: 0.274379\n",
      "[300]\ttraining's multi_error: 0.250175\n",
      "[400]\ttraining's multi_error: 0.232689\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[396]\ttraining's multi_error: 0.232453\n",
      "0.6844486843971174\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.30704\n",
      "[200]\ttraining's multi_error: 0.278227\n",
      "[300]\ttraining's multi_error: 0.258247\n",
      "[400]\ttraining's multi_error: 0.23755\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\ttraining's multi_error: 0.237526\n",
      "0.6833848635569297\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.306648\n",
      "[200]\ttraining's multi_error: 0.273097\n",
      "[300]\ttraining's multi_error: 0.250372\n",
      "[400]\ttraining's multi_error: 0.233054\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.233054\n",
      "0.6653171207279424\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.306333\n",
      "[200]\ttraining's multi_error: 0.279315\n",
      "[300]\ttraining's multi_error: 0.248041\n",
      "[400]\ttraining's multi_error: 0.23106\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\ttraining's multi_error: 0.230201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 14:04:44,756 - INFO - time:8 SEED:560 train score:0.767034 val score:0.678714 cost:457.687507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6789618798096048\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.306933\n",
      "[200]\ttraining's multi_error: 0.274241\n",
      "[300]\ttraining's multi_error: 0.248415\n",
      "[400]\ttraining's multi_error: 0.228055\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[398]\ttraining's multi_error: 0.228045\n",
      "0.6793647805507745\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.309641\n",
      "[200]\ttraining's multi_error: 0.27162\n",
      "[300]\ttraining's multi_error: 0.25202\n",
      "[400]\ttraining's multi_error: 0.233725\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.233725\n",
      "0.6748951832736028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.306739\n",
      "[200]\ttraining's multi_error: 0.27522\n",
      "[300]\ttraining's multi_error: 0.252398\n",
      "[400]\ttraining's multi_error: 0.235492\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[397]\ttraining's multi_error: 0.235039\n",
      "0.6875264606265876\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.307659\n",
      "[200]\ttraining's multi_error: 0.276028\n",
      "[300]\ttraining's multi_error: 0.256303\n",
      "[400]\ttraining's multi_error: 0.241458\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[388]\ttraining's multi_error: 0.2414\n",
      "0.6970663680516673\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.303829\n",
      "[200]\ttraining's multi_error: 0.272289\n",
      "[300]\ttraining's multi_error: 0.249134\n",
      "[400]\ttraining's multi_error: 0.234299\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\ttraining's multi_error: 0.234001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 14:05:31,681 - INFO - time:9 SEED:501 train score:0.765558 val score:0.683216 cost:504.612547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6764515520077667\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.303169\n",
      "[200]\ttraining's multi_error: 0.27609\n",
      "[300]\ttraining's multi_error: 0.253125\n",
      "[400]\ttraining's multi_error: 0.235354\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[395]\ttraining's multi_error: 0.235207\n",
      "0.6913721484508001\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.310441\n",
      "[200]\ttraining's multi_error: 0.277037\n",
      "[300]\ttraining's multi_error: 0.254563\n",
      "[400]\ttraining's multi_error: 0.231239\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's multi_error: 0.231239\n",
      "0.6771026904742667\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.31046\n",
      "[200]\ttraining's multi_error: 0.282017\n",
      "[300]\ttraining's multi_error: 0.259802\n",
      "[400]\ttraining's multi_error: 0.241539\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[397]\ttraining's multi_error: 0.241468\n",
      "0.713871199671323\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.304298\n",
      "[200]\ttraining's multi_error: 0.27626\n",
      "[300]\ttraining's multi_error: 0.256191\n",
      "[400]\ttraining's multi_error: 0.234467\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[397]\ttraining's multi_error: 0.234232\n",
      "0.6644227222427148\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_error: 0.299951\n",
      "[200]\ttraining's multi_error: 0.270864\n",
      "[300]\ttraining's multi_error: 0.249357\n",
      "[400]\ttraining's multi_error: 0.230666\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[396]\ttraining's multi_error: 0.230617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 14:06:18,513 - INFO - time:10 SEED:30 train score:0.765447 val score:0.682892 cost:551.444792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6661041297647108\n",
      "[0.6805258560166353, 0.6845614204329254, 0.681024272338966, 0.6824418112341967, 0.6858369374728684, 0.6860727473457991, 0.680761665889566, 0.6787144074473045, 0.6832162322941621, 0.6828919937188824] 0.6826047344191306\n"
     ]
    }
   ],
   "source": [
    "SEED = 42 \n",
    "\n",
    "params = {  \n",
    "    'boosting_type': 'gbdt',  \n",
    "    'objective': 'multiclass',  \n",
    "    'num_class': 5,  \n",
    "    'metric': 'multi_error',  \n",
    "    'num_leaves': 8,  \n",
    "    'max_depth': 3,\n",
    "    'min_data_in_leaf': 100,  \n",
    "    'learning_rate': 0.01,  \n",
    "    'feature_fraction': 0.8,  \n",
    "    'bagging_fraction': 0.8,  \n",
    "    'bagging_freq': 5,  \n",
    "    'lambda_l1': 0.5,  \n",
    "    'lambda_l2': 0.5,  \n",
    "    'min_gain_to_split': 0.2,  \n",
    "    'verbose': -1, \n",
    "    \n",
    "    'feature_fraction_seed':SEED,\n",
    "    'bagging_seed':SEED,\n",
    "} \n",
    "\n",
    "def fit_lgb(train_x, train_y):\n",
    "    class_weights = [1,10,50,100,300]\n",
    "    trn_data = lgb.Dataset(train_x, train_y, weight=[class_weights[int(y)] for y in train_y])\n",
    "    clf = lgb.train(params, \n",
    "                    trn_data, \n",
    "                    num_boost_round = 400,\n",
    "                    valid_sets = [trn_data], \n",
    "                    verbose_eval = 100, \n",
    "                    early_stopping_rounds = 100\n",
    "                   )\n",
    "    return clf\n",
    "\n",
    "def eval_logit(logit, label):\n",
    "    prediction = np.argmax(logit, 1)\n",
    "    return precision_score_cch(prediction+1, np.array(label).astype('int')+1)\n",
    "    \n",
    "def cross_validation_lgb(train_x, train_y, test_x):\n",
    "    n_flod = 5\n",
    "    folds = KFold(n_splits=n_flod, shuffle=True,random_state=SEED)\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "    score_train = np.zeros((len(train_x), 5))\n",
    "    score_test = np.zeros((len(test_x), 5))\n",
    "    trainset_score_list = []\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train_x, train_y)):\n",
    "        \n",
    "        trn_x, trn_labels = train_x[trn_idx], train_y[trn_idx]\n",
    "        val_x, val_labels = train_x[val_idx], train_y[val_idx]\n",
    "        model = fit_lgb(trn_x, trn_labels)\n",
    "        score_train[val_idx] = model.predict(val_x)\n",
    "        score_test += model.predict(test_x)/n_flod\n",
    "        \n",
    "        train_score = eval_logit(model.predict(trn_x), trn_labels)\n",
    "        trainset_score_list.append(train_score)\n",
    "        print(eval_logit(score_train[val_idx], val_labels))\n",
    "        \n",
    "    return score_train, score_test, np.mean(trainset_score_list)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "score_list = []\n",
    "for t in range(10):\n",
    "    SEED = random.randint(0, 1314)\n",
    "    score_train, score_test, avg_train_score = cross_validation_lgb(train_x, train_y, test_x)\n",
    "    prediction = np.argmax(score_train, 1)\n",
    "    score = precision_score_cch(prediction+1, np.array(train_y).astype('int')+1)\n",
    "    logging.info('time:%d SEED:%d train score:%f val score:%f cost:%f'%(t+1, SEED, avg_train_score, score, time.time()-start))\n",
    "\n",
    "    score_list.append(score)\n",
    "print(score_list, np.mean(score_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0.6862871199575542, 0.684322930902348, 0.6829616648177029, 0.6900011254562117, 0.6829268292682927, 0.6821577675236212, 0.6878707976268952, 0.6875411997363217, 0.6877180571410196, 0.6869677529998768] 0.6858755245429844\n",
    "\n",
    "[0.6847195202340949, 0.6796978418037312, 0.682825002277709, 0.6853063652587745, 0.6847811523599745, 0.68440867994705, 0.6821765251271498, 0.6809840774742619, 0.6877234164563135, 0.6839477788317765] 0.6836570359770836\n",
    "\n",
    "[0.6855180582128827, 0.6808179387001516, 0.6869918699186992, 0.6889426606856708, 0.6891409553515443, 0.6861584963905012, 0.6742876130145613, 0.684320251244701, 0.6821926030730314, 0.6869248784775257] 0.6845295325069269\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict                                      0\n",
       "label                                      4.0\n",
       "score      [0.379, 0.299, 0.238, 0.052, 0.032]\n",
       "Name: 008aa2a00173766f0637eeb05644427c14b827c4, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weibo_with_repost['predict'] = list(np.argmax(np.concatenate([score_train, score_test]), 1))\n",
    "df_weibo_with_repost['score'] = list(np.round( np.concatenate([score_train, score_test]),3))\n",
    "\n",
    "df_weibo_with_repost.loc['008aa2a00173766f0637eeb05644427c14b827c4'][['predict','label','score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.492667\n",
      "0    0.295000\n",
      "2    0.152333\n",
      "4    0.032722\n",
      "3    0.027278\n",
      "dtype: float64\n",
      "baseline 0.6859977169316848\n",
      "1    0.203389\n",
      "4    0.201222\n",
      "0    0.199833\n",
      "3    0.198944\n",
      "2    0.196611\n",
      "dtype: float64\n",
      "randon 0.18285179885417838\n",
      "1    0.492667\n",
      "0    0.295000\n",
      "2    0.152333\n",
      "4    0.032722\n",
      "3    0.027278\n",
      "dtype: float64\n",
      "random shuffle 0.14386545974886247\n"
     ]
    }
   ],
   "source": [
    "prediction = np.argmax(score_train, 1)\n",
    "print(pd.Series(prediction).value_counts(1))\n",
    "print('baseline', precision_score_cch(prediction+1, np.array(train_y).astype('int')+1))\n",
    "\n",
    "\n",
    "prediction_random = np.array([random.randint(0,4) for i in range(18000)])\n",
    "print(pd.Series(prediction_random).value_counts(1))\n",
    "print('randon', precision_score_cch(prediction_random+1, np.array(train_y).astype('int')+1))\n",
    "\n",
    "\n",
    "prediction_shuffle = prediction[:]\n",
    "random.shuffle(prediction_shuffle)\n",
    "print(pd.Series(prediction_shuffle).value_counts(1))\n",
    "print('random shuffle', precision_score_cch(prediction_shuffle+1, np.array(train_y).astype('int')+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提交文件、融合文件生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediciton_test = np.argmax(score_test, 1)\n",
    "# df_submit = pd.DataFrame({\n",
    "#     'WeiboId':list(df_weibo_with_repost.query('type==\"test\"')['WeiboId']),\n",
    "#     'ForwardScale':prediciton_test+1\n",
    "# })\n",
    "# SUBMIT_PATH = '/data/cch/hyr/weibo/submit'\n",
    "# df_submit.to_csv('%s/submission.csv'%SUBMIT_PATH, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_OUT_PATH = 'sub_model_output'\n",
    "\n",
    "df_model_output = pd.DataFrame({\n",
    "    'WeiboId':train_weibo_ids+test_weibo_ids,\n",
    "    'lgb_hyr_0':np.concatenate([score_train[:, 0], score_test[:, 0]]),\n",
    "    'lgb_hyr_1':np.concatenate([score_train[:, 1], score_test[:, 1]]),\n",
    "    'lgb_hyr_2':np.concatenate([score_train[:, 2], score_test[:, 2]]),\n",
    "    'lgb_hyr_3':np.concatenate([score_train[:, 3], score_test[:, 3]]),\n",
    "    'lgb_hyr_4':np.concatenate([score_train[:, 4], score_test[:, 4]])\n",
    "})\n",
    "\n",
    "pickle.dump(df_model_output, open('%s/df_lgb.pickle'%MODEL_OUT_PATH, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_feature_importances():\n",
    "    \n",
    "    class_weights = [1,10,50,100,300]\n",
    "    trn_data = lgb.Dataset(train_x, np.array(train_y).astype('int'),\n",
    "                           weight=[class_weights[int(y)] for y in train_y],\n",
    "                          feature_name=feature_name_list)\n",
    "    clf = lgb.train(params, \n",
    "                    trn_data, \n",
    "                    num_boost_round = 100,\n",
    "                    valid_sets = [trn_data], \n",
    "                    verbose_eval = 100, \n",
    "                    early_stopping_rounds = 100\n",
    "                   )\n",
    "\n",
    "    importance_dict = {}\n",
    "    for name, importance in zip(feature_name_list, clf.feature_importance()):\n",
    "        importance_dict[name] = importance\n",
    "    print(importance_dict)\n",
    "    print(lgb.plot_importance(clf,max_num_features=30))\n",
    "check_feature_importances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyr2",
   "language": "python",
   "name": "hyr2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.432px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
