{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cch/anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/cch/anaconda3/lib/python3.7/site-packages/dask/config.py:161: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/home/cch/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "/home/cch/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "from gensim.models.word2vec import Word2Vec \n",
    "import jieba\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import IPython.display as ipd\n",
    "from collections import *\n",
    "import torch\n",
    "from transformers import *\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/data/cch/weibo'\n",
    "VAR_PATH = '/data/cch/hyr/weibo/var'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_origin_weibo = pd.read_csv('%s/test.origin_weibo.csv'%DATA_PATH, sep='\\t')\n",
    "df_test_repost = pd.read_csv('%s/test.repost.csv'%DATA_PATH, sep='\\t')\n",
    "df_train_origin_weibo = pd.read_csv('%s/train.origin_weibo.csv'%DATA_PATH, sep='\\t')\n",
    "df_train_repost = pd.read_csv('%s/train.repost.csv'%DATA_PATH, sep='\\t')\n",
    "# df_user_profile = pd.read_csv('%s/user_profile.csv'%DATA_PATH, sep='\\t')\n",
    "df_user_profile_agg = pickle.load(open('%s/df_user_profile_agg.pickle'%VAR_PATH, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count2idx(num):\n",
    "    if 0 <= num <= 10:\n",
    "        return 0\n",
    "    elif 11 <= num <= 50:\n",
    "        return 1\n",
    "    elif 51 <= num <= 150:\n",
    "        return 2\n",
    "    elif 151 <= num <= 300:\n",
    "        return 3\n",
    "    elif num > 300:\n",
    "        return 4\n",
    "    \n",
    "df_train_origin_weibo['label'] = df_train_origin_weibo['ForwordCount'].apply(count2idx)\n",
    "df_train_origin_weibo['type'] = 'train'\n",
    "df_test_origin_weibo['type'] = 'test'\n",
    "df_origin_weibo = pd.concat([df_train_origin_weibo, df_test_origin_weibo])\n",
    "df_weibo = pd.merge(df_origin_weibo, df_user_profile_agg, how='left', on='UserId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 转发特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def apply_pass_time(a_row):\n",
    "    global mp_WeiboId_create_time\n",
    "    repost_date_obj = datetime.strptime(a_row['RepostDate'], '%Y-%m-%d %H:%M:%S')\n",
    "    post_date_obj = datetime.strptime(mp_WeiboId_create_time[a_row['OriginWeiboId']], '%Y-%m-%d %H:%M:%S')\n",
    "    return (repost_date_obj-post_date_obj).seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mp_WeiboId_create_time = dict(list(df_weibo[['WeiboId', 'WeiboCreateTime']].values))\n",
    "df_train_repost['pass_time'] = df_train_repost.apply(apply_pass_time, 1)\n",
    "df_test_repost['pass_time'] = df_test_repost.apply(apply_pass_time, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_24h_repost_features(df_repost):\n",
    "    ret_dict_list = []\n",
    "    \n",
    "    for weibo_id, df in tqdm(df_repost.groupby('OriginWeiboId')):\n",
    "        ret_dict = {'WeiboId':weibo_id}\n",
    "        for hour in range(2, 25):\n",
    "            ddl = 3600*hour\n",
    "            df_sub = df.query('pass_time < @ddl')\n",
    "            ret_dict['24h_%d_reposet_cnt'%hour] = df_sub.shape[0]\n",
    "                \n",
    "        ret_dict_list.append(ret_dict)\n",
    "    return pd.DataFrame(ret_dict_list)\n",
    "\n",
    "df_repost_24h_origin = get_24h_repost_features(df_train_repost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(df_repost_24h_origin, open('%s/df_repost_24h_origin.pickle'%VAR_PATH, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉验证预测测试集24h数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repost_24h_origin = pickle.load(open('%s/df_repost_24h_origin.pickle'%VAR_PATH, 'rb'))\n",
    "df_weibo = pickle.load(open('%s/df_all.pickle'%VAR_PATH, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "continue_feature_list = [\n",
    "\n",
    "    #文本硬特征\n",
    "    'weibotext_len', \n",
    "    \n",
    "    #性别\n",
    "    'Gender', \n",
    "    \n",
    "    #用户粉丝，关注数\n",
    "    'follow_mean', 'follow_median', 'follow_max', 'follow_min', 'follower_mean',\n",
    "    'follower_median', 'follower_max', 'follower_min',\n",
    "    \n",
    "    #user id target encode\n",
    "    'target_encode_0', 'target_encode_1', 'target_encode_2', 'target_encode_3', 'target_encode_4',\n",
    "    'target_encode_cnt', \n",
    "    \n",
    "    #转发特征(微博维度)\n",
    "     'repost_weibo_cnt_15_30_mins', 'repost_weibo_cnt_15_mins','repost_weibo_cnt_30_45_mins','repost_weibo_cnt_30_mins',\n",
    "     'repost_weibo_cnt_45_60_mins','repost_weibo_cnt_45_mins','repost_weibo_cnt_60_mins',\n",
    "     'repost_weibo_follow_max_max',\n",
    "     'repost_weibo_follow_max_mean','repost_weibo_follow_max_min','repost_weibo_follow_max_sum','repost_weibo_follow_mean_max',\n",
    "     'repost_weibo_follow_mean_mean','repost_weibo_follow_mean_min','repost_weibo_follow_mean_sum','repost_weibo_follow_median_max',\n",
    "     'repost_weibo_follow_median_mean','repost_weibo_follow_median_min','repost_weibo_follow_median_sum',\n",
    "     'repost_weibo_follow_min_max', 'repost_weibo_follow_min_mean','repost_weibo_follow_min_min','repost_weibo_follow_min_sum',\n",
    "     'repost_weibo_follower_max_max','repost_weibo_follower_max_mean','repost_weibo_follower_max_min',\n",
    "     'repost_weibo_follower_max_sum','repost_weibo_follower_mean_max','repost_weibo_follower_mean_mean',\n",
    "     'repost_weibo_follower_mean_min','repost_weibo_follower_mean_sum','repost_weibo_follower_median_max',\n",
    "     'repost_weibo_follower_median_mean','repost_weibo_follower_median_min','repost_weibo_follower_median_sum',\n",
    "     'repost_weibo_follower_min_max','repost_weibo_follower_min_mean','repost_weibo_follower_min_min',\n",
    "     'repost_weibo_follower_min_sum','repost_weibo_pass_time_max','repost_weibo_pass_time_mean','repost_weibo_pass_time_median',\n",
    "     'repost_weibo_pass_time_min', 'repost_weibo_Verified', 'repost_weibo_Gender',\n",
    "    \n",
    "    #水军\n",
    "     'repost_weibo_unique_repost_userid',\n",
    "     'repost_weibo_repeat_repost_cnt',\n",
    "     'repost_weibo_max_user_repost',\n",
    "     'repost_weibo_other_cnt_max',\n",
    "     'repost_weibo_other_cnt_min',\n",
    "     'repost_weibo_other_cnt_mean',\n",
    "     'repost_weibo_other_cnt_std',\n",
    "     'repost_weibo_other_cnt_0',\n",
    "     'repost_weibo_text_len_max',\n",
    "     'repost_weibo_text_len_min',\n",
    "     'repost_weibo_text_len_mean',\n",
    "     'repost_weibo_text_len_std',\n",
    "\n",
    "    #转发特征(用户维度)    \n",
    "     'repost_userid_cnt_15_30_mins','repost_userid_cnt_15_mins','repost_userid_cnt_30_45_mins','repost_userid_cnt_30_mins',\n",
    "     'repost_userid_cnt_45_60_mins','repost_userid_cnt_45_mins','repost_userid_cnt_60_mins','repost_userid_follow_max_max',\n",
    "     'repost_userid_follow_max_mean','repost_userid_follow_max_min','repost_userid_follow_max_sum','repost_userid_follow_mean_max',\n",
    "     'repost_userid_follow_mean_mean','repost_userid_follow_mean_min','repost_userid_follow_mean_sum',\n",
    "     'repost_userid_follow_median_max','repost_userid_follow_median_mean','repost_userid_follow_median_min',\n",
    "     'repost_userid_follow_median_sum','repost_userid_follow_min_max','repost_userid_follow_min_mean',\n",
    "     'repost_userid_follow_min_min','repost_userid_follow_min_sum','repost_userid_follower_max_max',\n",
    "     'repost_userid_follower_max_mean','repost_userid_follower_max_min','repost_userid_follower_max_sum',\n",
    "     'repost_userid_follower_mean_max','repost_userid_follower_mean_mean','repost_userid_follower_mean_min',\n",
    "     'repost_userid_follower_mean_sum','repost_userid_follower_median_max','repost_userid_follower_median_mean',\n",
    "     'repost_userid_follower_median_min','repost_userid_follower_median_sum','repost_userid_follower_min_max',\n",
    "     'repost_userid_follower_min_mean','repost_userid_follower_min_min','repost_userid_follower_min_sum',\n",
    "     'repost_userid_pass_time_max','repost_userid_pass_time_mean','repost_userid_pass_time_median',\n",
    "     'repost_userid_pass_time_min', 'repost_userid_Verified', 'repost_userid_Gender',\n",
    "        \n",
    "     'repost_userid_unique_repost_userid',\n",
    "     'repost_userid_repeat_repost_cnt',\n",
    "     'repost_userid_max_user_repost',\n",
    "     'repost_userid_other_cnt_max',\n",
    "     'repost_userid_other_cnt_mean',\n",
    "     'repost_userid_other_cnt_std',\n",
    "     'repost_userid_other_cnt_0',\n",
    "     'repost_userid_text_len_max',\n",
    "     'repost_userid_text_len_min',\n",
    "     'repost_userid_text_len_mean',\n",
    "     'repost_userid_text_len_std',\n",
    "    \n",
    "    \n",
    "    #交叉特征 24h转发特征 target encode\n",
    "    'target_encode_24h_10_reposet_cnt',\n",
    "       'target_encode_24h_11_reposet_cnt', 'target_encode_24h_12_reposet_cnt',\n",
    "       'target_encode_24h_13_reposet_cnt', 'target_encode_24h_14_reposet_cnt',\n",
    "       'target_encode_24h_15_reposet_cnt', 'target_encode_24h_16_reposet_cnt',\n",
    "       'target_encode_24h_17_reposet_cnt', 'target_encode_24h_18_reposet_cnt',\n",
    "       'target_encode_24h_19_reposet_cnt', 'target_encode_24h_20_reposet_cnt',\n",
    "       'target_encode_24h_21_reposet_cnt', 'target_encode_24h_22_reposet_cnt',\n",
    "       'target_encode_24h_23_reposet_cnt', 'target_encode_24h_24_reposet_cnt',\n",
    "       'target_encode_24h_2_reposet_cnt', 'target_encode_24h_3_reposet_cnt',\n",
    "       'target_encode_24h_4_reposet_cnt', 'target_encode_24h_5_reposet_cnt',\n",
    "       'target_encode_24h_6_reposet_cnt', 'target_encode_24h_7_reposet_cnt',\n",
    "       'target_encode_24h_8_reposet_cnt', 'target_encode_24h_9_reposet_cnt'\n",
    "]\n",
    "\n",
    "cat_feature_list = [\n",
    "    \n",
    "    #文本特征\n",
    "    'is_video',\n",
    "\n",
    "    #发表日期特征\n",
    "    'post_day', 'post_weekday', 'post_month', 'post_hour',\n",
    "    \n",
    "    #交叉特征\n",
    "    'userid_idx', \n",
    "    'cross_userid_idx_post_hour',\n",
    "    'cross_userid_idx_post_weekday', \n",
    "    'cross_repost_1h_cnt_idx_post_hour', 'cross_repost_1h_cnt_idx_post_weekday',\n",
    "]\n",
    "\n",
    "hidden_feature_list = [\n",
    "    'weibotext_wv_embed', 'weibotext_tfidf',#微博内容词向量/tfidf+svd降维\n",
    "    'user_intro_wv_embed', 'user_intro_tfidf'#用户个性签名词向量/tfidf+svd降维\n",
    "]\n",
    "\n",
    "def generate_one_hot(df_weibo):\n",
    "    global cat_feature_list\n",
    "    \n",
    "    cut_one_hot_feature_list = [    \n",
    "        #转发特征(微博维度)\n",
    "         'repost_weibo_cnt_15_30_mins', 'repost_weibo_cnt_15_mins','repost_weibo_cnt_30_45_mins','repost_weibo_cnt_30_mins',\n",
    "         'repost_weibo_cnt_45_60_mins','repost_weibo_cnt_45_mins','repost_weibo_cnt_60_mins','repost_weibo_follow_max_max',\n",
    "         'repost_weibo_follow_max_mean','repost_weibo_follow_max_min','repost_weibo_follow_max_sum','repost_weibo_follow_mean_max',\n",
    "         'repost_weibo_follow_mean_mean','repost_weibo_follow_mean_min','repost_weibo_follow_mean_sum','repost_weibo_follow_median_max',\n",
    "         'repost_weibo_follow_median_mean','repost_weibo_follow_median_min','repost_weibo_follow_median_sum',\n",
    "         'repost_weibo_follow_min_max', 'repost_weibo_follow_min_mean','repost_weibo_follow_min_min','repost_weibo_follow_min_sum',\n",
    "         'repost_weibo_follower_max_max','repost_weibo_follower_max_mean','repost_weibo_follower_max_min',\n",
    "         'repost_weibo_follower_max_sum','repost_weibo_follower_mean_max','repost_weibo_follower_mean_mean',\n",
    "         'repost_weibo_follower_mean_min','repost_weibo_follower_mean_sum','repost_weibo_follower_median_max',\n",
    "         'repost_weibo_follower_median_mean','repost_weibo_follower_median_min','repost_weibo_follower_median_sum',\n",
    "         'repost_weibo_follower_min_max','repost_weibo_follower_min_mean','repost_weibo_follower_min_min',\n",
    "         'repost_weibo_follower_min_sum','repost_weibo_pass_time_max','repost_weibo_pass_time_mean','repost_weibo_pass_time_median',\n",
    "         'repost_weibo_pass_time_min', 'repost_weibo_Verified', 'repost_weibo_Gender',\n",
    "\n",
    "         'repost_weibo_unique_repost_userid',\n",
    "         'repost_weibo_repeat_repost_cnt',\n",
    "         'repost_weibo_max_user_repost',\n",
    "         'repost_weibo_other_cnt_max',\n",
    "         'repost_weibo_other_cnt_min',\n",
    "         'repost_weibo_other_cnt_mean',\n",
    "         'repost_weibo_other_cnt_std',\n",
    "         'repost_weibo_other_cnt_0',\n",
    "         'repost_weibo_text_len_max',\n",
    "         'repost_weibo_text_len_min',\n",
    "         'repost_weibo_text_len_mean',\n",
    "         'repost_weibo_text_len_std',\n",
    "\n",
    "        #转发特征(用户维度)    \n",
    "         'repost_userid_cnt_15_30_mins','repost_userid_cnt_15_mins','repost_userid_cnt_30_45_mins','repost_userid_cnt_30_mins',\n",
    "         'repost_userid_cnt_45_60_mins','repost_userid_cnt_45_mins','repost_userid_cnt_60_mins','repost_userid_follow_max_max',\n",
    "         'repost_userid_follow_max_mean','repost_userid_follow_max_min','repost_userid_follow_max_sum','repost_userid_follow_mean_max',\n",
    "         'repost_userid_follow_mean_mean','repost_userid_follow_mean_min','repost_userid_follow_mean_sum',\n",
    "         'repost_userid_follow_median_max','repost_userid_follow_median_mean','repost_userid_follow_median_min',\n",
    "         'repost_userid_follow_median_sum','repost_userid_follow_min_max','repost_userid_follow_min_mean',\n",
    "         'repost_userid_follow_min_min','repost_userid_follow_min_sum','repost_userid_follower_max_max',\n",
    "         'repost_userid_follower_max_mean','repost_userid_follower_max_min','repost_userid_follower_max_sum',\n",
    "         'repost_userid_follower_mean_max','repost_userid_follower_mean_mean','repost_userid_follower_mean_min',\n",
    "         'repost_userid_follower_mean_sum','repost_userid_follower_median_max','repost_userid_follower_median_mean',\n",
    "         'repost_userid_follower_median_min','repost_userid_follower_median_sum','repost_userid_follower_min_max',\n",
    "         'repost_userid_follower_min_mean','repost_userid_follower_min_min','repost_userid_follower_min_sum',\n",
    "         'repost_userid_pass_time_max','repost_userid_pass_time_mean','repost_userid_pass_time_median',\n",
    "         'repost_userid_pass_time_min', 'repost_userid_Verified', 'repost_userid_Gender',\n",
    "\n",
    "         'repost_userid_unique_repost_userid',\n",
    "         'repost_userid_repeat_repost_cnt',\n",
    "         'repost_userid_max_user_repost',\n",
    "         'repost_userid_other_cnt_max',\n",
    "    #      'repost_userid_other_cnt_min',\n",
    "         'repost_userid_other_cnt_mean',\n",
    "         'repost_userid_other_cnt_std',\n",
    "         'repost_userid_other_cnt_0',\n",
    "         'repost_userid_text_len_max',\n",
    "         'repost_userid_text_len_min',\n",
    "         'repost_userid_text_len_mean',\n",
    "         'repost_userid_text_len_std',\n",
    "    ]\n",
    "\n",
    "    one_hot_feature_name_list = []\n",
    "    df_one_hot_list = []\n",
    "    for f in cat_feature_list:\n",
    "        df_one_hot = pd.get_dummies(df_weibo[f])\n",
    "        one_hot_feature_name = ['%s_%s'%(f, name) for name in df_one_hot.columns]\n",
    "        one_hot_feature_name_list.extend(one_hot_feature_name)\n",
    "        df_one_hot.columns = one_hot_feature_name \n",
    "        df_one_hot_list.append(df_one_hot)\n",
    "\n",
    "    cut_num = 5\n",
    "    for f in cut_one_hot_feature_list:\n",
    "        df_one_hot = pd.get_dummies(pd.qcut(df_weibo[f], cut_num, duplicates=\"drop\"))\n",
    "        one_hot_feature_name = ['%s_qcut_%s'%(f, name) for name in df_one_hot.columns]\n",
    "        one_hot_feature_name_list.extend(one_hot_feature_name)\n",
    "        df_one_hot.columns = one_hot_feature_name \n",
    "        df_one_hot_list.append(df_one_hot)\n",
    "\n",
    "        df_one_hot = pd.get_dummies(pd.cut(df_weibo[f], cut_num))\n",
    "        one_hot_feature_name = ['%s_cut_%s'%(f, name) for name in df_one_hot.columns]\n",
    "        one_hot_feature_name_list.extend(one_hot_feature_name)\n",
    "        df_one_hot.columns = one_hot_feature_name \n",
    "        df_one_hot_list.append(df_one_hot)\n",
    "    return pd.concat(df_one_hot_list, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cch/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:195: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "/home/cch/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  app.launch_new_instance()\n",
      "/home/cch/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    }
   ],
   "source": [
    "dense_mean = np.array(df_weibo[continue_feature_list].mean()) \n",
    "dense_std = np.array(df_weibo[continue_feature_list].std())\n",
    "\n",
    "forword_cnt_mean = df_weibo.query('type==\"train\"')['ForwordCount'].mean()\n",
    "forword_cnt_std = df_weibo.query('type==\"train\"')['ForwordCount'].std()\n",
    "\n",
    "mp_userid_idx = dict([(userid,i) for i, userid in enumerate(set(df_weibo['UserId']))])\n",
    "\n",
    "df_weibo.index = df_weibo.WeiboId\n",
    "\n",
    "# df_weibo['sample_weight'] = df_weibo['label'].map({0:1,1:10,2:50,3:100,4:300,-1:0})\n",
    "df_weibo['sample_weight'] = df_weibo['label'].map({0:0.00333333,1:0.03333333,2:0.16666667,3:0.33333333,4:1,-1:0})\n",
    "\n",
    "df_weibo_one_hot = generate_one_hot(df_weibo)\n",
    "one_hot_feature_list = list(df_weibo_one_hot.columns)\n",
    "df_weibo = pd.concat([df_weibo, df_weibo_one_hot], 1)\n",
    "\n",
    "df_repost_24h_origin.index = df_repost_24h_origin['WeiboId']\n",
    "df_repost_24h_origin = df_repost_24h_origin.drop('WeiboId', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count2idx(num):\n",
    "    if 0 <= num <= 10:\n",
    "        return 0\n",
    "    elif 10 <= num <= 50:\n",
    "        return 1\n",
    "    elif 50 <= num <= 150:\n",
    "        return 2\n",
    "    elif 150 <= num <= 300:\n",
    "        return 3\n",
    "    elif num >= 300:\n",
    "        return 4\n",
    "    if num < 0:\n",
    "        print(num)\n",
    "        return 0\n",
    "    print(num)\n",
    "\n",
    "def get_distibution(cnt):\n",
    "    ret = np.zeros(5)\n",
    "    if cnt > 400:\n",
    "        cnt = 400\n",
    "    ll = [-10,11,51,151,301]\n",
    "    rr = [10,50,150,300,500]\n",
    "    median = [(l+r)//2 for l,r in zip(ll, rr)]\n",
    "    interval_length = [r-l+3 for l, r in zip(ll, rr)]\n",
    "    eps = 1e-8\n",
    "    for i in range(5):\n",
    "        dis = abs(cnt - median[i])/interval_length[i]\n",
    "        ret[i] = 1/(dis+eps)\n",
    "    return ret/sum(ret)\n",
    "\n",
    "def get_mp_distibution(func_name):\n",
    "    ret = {}\n",
    "    for i in range(0, 500):\n",
    "        ret[i] = func_name(i)\n",
    "    return ret\n",
    "\n",
    "mp_distibution = get_mp_distibution(get_distibution)\n",
    "mp_distibution[-1] = mp_distibution[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repost_24h_label = pd.DataFrame()\n",
    "for i in range(2, 25):\n",
    "    df_repost_24h_label[i] = df_repost_24h_origin['24h_%d_reposet_cnt'%i].apply(count2idx)\n",
    "df_repost_24h_label.index = df_repost_24h_origin.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_repost_24h_origin_soft = pd.DataFrame()\n",
    "for i in range(2, 25):\n",
    "    df_repost_24h_origin_soft[i] =\\\n",
    "    df_repost_24h_origin['24h_%d_reposet_cnt'%i].apply(lambda x:mp_distibution.get(x, -1) if x < 400 else mp_distibution[400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "df_weibo['1h_cnt_soft'] = \\\n",
    "df_weibo['repost_weibo_cnt_60_mins'].apply(lambda x:mp_distibution.get(x, -1) if x < 400 else mp_distibution[400])\n",
    "\n",
    "def apply_1h_cnt_hard(x):\n",
    "    label = count2idx(x)\n",
    "    ret = np.zeros(5)\n",
    "    ret[label] = 1.\n",
    "    return ret\n",
    "df_weibo['1h_cnt_hard'] = \\\n",
    "df_weibo['repost_weibo_cnt_60_mins'].apply(apply_1h_cnt_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class WeiboDataset(Data.Dataset):\n",
    "    def __init__(self, weibo_id):\n",
    "        self.weibo_id = weibo_id\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.weibo_id)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.weibo_id[idx]\n",
    "\n",
    "def collate_fn(weibo_ids, mask_24h=False):\n",
    "\n",
    "    global dense_mean, dense_std, df_weibo, albert_tokenizer, mp_userid_idx, one_hot_feature_list, df_repost_24h_origin_soft\n",
    "        \n",
    "    df_weibo_sub = df_weibo.loc[weibo_ids]\n",
    "    #连续性特征归一化\n",
    "    dense = (np.array(df_weibo_sub[continue_feature_list].values) - dense_mean) /dense_std \n",
    "    \n",
    "    #标签\n",
    "    y = np.array(df_weibo_sub['label'])\n",
    "    forword_cnt = np.array(df_weibo_sub['ForwordCount'])\n",
    "    #样本权重\n",
    "    sample_weight = np.array(df_weibo_sub['sample_weight'])\n",
    "    cal_loss = df_weibo.at[weibo_ids[0], 'label'] != -1\n",
    "    \n",
    "    #序列文本特征用于bert encoder\n",
    "    #微博正文\n",
    "#     df_weibo_text = df_weibo_sub['WeiboText']\n",
    "#     max_length = min(args.weibo_text_max_length, max(df_weibo_text.apply(len)))\n",
    "#     weibotext_tokenized_list = []\n",
    "#     for sentence in df_weibo_text:\n",
    "#         sentence = list(sentence)\n",
    "#         if len(sentence) > max_length:\n",
    "#             text = sentence[:max_length]\n",
    "#         else:\n",
    "#             text = sentence + ['<pad>']*(max_length-len(sentence))\n",
    "#         weibotext_tokenized_list.append(albert_tokenizer.encode(text))        \n",
    "    \n",
    "    #用户简介\n",
    "#     max_length = max(df_weibo_sub['intro'].apply(len))\n",
    "#     intro_tokenized_list = []\n",
    "#     for sentence in df_weibo_sub['intro']:\n",
    "#         sentence = list(sentence)\n",
    "#         if len(sentence) > max_length:\n",
    "#             text = sentence[:max_length]\n",
    "#         else:\n",
    "#             text = sentence + ['<pad>']*(max_length-len(sentence))\n",
    "#         intro_tokenized_list.append(albert_tokenizer.encode(text))        \n",
    "    \n",
    "    #固定文本特征\n",
    "    text_feature_list = []\n",
    "    for f in ['weibotext_wv_embed', 'weibotext_tfidf', 'user_intro_wv_embed', 'user_intro_tfidf']:\n",
    "        hidden_train = np.array(list(df_weibo_sub[f]))\n",
    "        text_feature_list.append(hidden_train)\n",
    "    text_hidden = np.concatenate(text_feature_list, 1)\n",
    "    \n",
    "    user_id_token = np.array(df_weibo_sub['UserId'].map(mp_userid_idx))\n",
    "    \n",
    "    #转发用户+转发文本 聚合\n",
    "    max_repost_user_set = 512\n",
    "    np_repost_text_wv = np.zeros((len(weibo_ids), max_repost_user_set, 10))\n",
    "    np_repost_user_dense = np.zeros((len(weibo_ids), max_repost_user_set, 8))\n",
    "    np_repost_user_id = np.zeros((len(weibo_ids), max_repost_user_set)).astype('int')\n",
    "    np_repost_set_len = np.zeros((len(weibo_ids),))\n",
    "    for i, weiboid in enumerate(weibo_ids):\n",
    "        userid_set_len = min(max_repost_user_set, df_weibo_sub.at[weiboid, 'repost_weibo_set_len'])\n",
    "        np_repost_text_wv[i,:userid_set_len,:] = np.array(df_weibo_sub.at[weiboid, 'repost_weibo_repost_text_wv'])[:userid_set_len]\n",
    "        np_repost_user_id[i,:userid_set_len] = np.array(df_weibo_sub.at[weiboid, 'repost_weibo_repost_user_id_freq'])[:userid_set_len]\n",
    "        np_repost_set_len[i] = userid_set_len\n",
    "        np_repost_user_dense[i,:userid_set_len] = np.array(df_weibo_sub.at[weiboid, 'repost_weibo_set_user_dense'])[:userid_set_len]\n",
    "    \n",
    "    \n",
    "    ret_dict = {}\n",
    "    if cal_loss:\n",
    "        df_24h_soft_sub = df_repost_24h_origin_soft.loc[weibo_ids]\n",
    "        df_repost_24h_label_sub = df_repost_24h_label.loc[weibo_ids]\n",
    "        for i in range(2, 25):\n",
    "            ret_dict['24_h_%d'%i] = torch.tensor(np.array(list(df_24h_soft_sub[i]))).float().to(args.device)\n",
    "            ret_dict['24_h_%d_label'%i] = torch.tensor(np.array(list(df_repost_24h_label_sub[i]))).long().to(args.device)\n",
    "    \n",
    "    ret_dict.update({\n",
    "        'cal_loss':cal_loss,\n",
    "        'mask_24h':mask_24h,\n",
    "        'x_dense':torch.tensor(dense).float().to(args.device), \n",
    "        'label':torch.tensor(y).long().to(args.device),\n",
    "        'forword_cnt' : torch.tensor(forword_cnt).float().to(args.device),\n",
    "        'sample_weight':torch.tensor(sample_weight).float().to(args.device),\n",
    "#         'weibo_text_token':torch.tensor(weibotext_tokenized_list).to(args.device),\n",
    "#         'intro_text_token':torch.tensor(intro_tokenized_list).to(args.device),\n",
    "        'text_wv_tfidf':torch.tensor(text_hidden).float().to(args.device),\n",
    "        'user_id_token':torch.tensor(user_id_token).long().to(args.device),\n",
    "        \n",
    "        'repost_set_text_wv':torch.tensor(np_repost_text_wv).float().to(args.device),\n",
    "        'repost_set_userid':torch.tensor(np_repost_user_id).long().to(args.device),\n",
    "        'repost_set_len' : torch.tensor(np_repost_set_len).long().to(args.device),\n",
    "        'repost_user_dense':torch.tensor(np_repost_user_dense).float().to(args.device),\n",
    "        'one_hot_feature':torch.tensor(np.array(df_weibo_sub[one_hot_feature_list])).float().to(args.device),\n",
    "        '1h_cnt_soft':torch.tensor(np.array(list(df_weibo_sub['1h_cnt_soft']))).float().to(args.device),\n",
    "        '1h_cnt_hard':torch.tensor(np.array(list(df_weibo_sub['1h_cnt_hard']))).float().to(args.device),\n",
    "    })\n",
    "    \n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 表示feature_len=100, hidden_len=20\n",
    "# cell = nn.RNNCell(100, 20)\n",
    "# # 某一时刻的输入, 共3个样本序列(batch=3), 每个特征100维度(feature_len=100)\n",
    "# x = torch.randn(3, 100)\n",
    "# # 所有时刻的输入, 一共有10个时刻, 即seq_len=10\n",
    "# xs = [torch.randn(3, 100) for i in range(10)]\n",
    "# # 初始化隐藏记忆单元, batch=3, hidden_len=20\n",
    "# h = torch.zeros(3, 20)\n",
    "# # 对每个时刻的输入, 传入这个nn.RNNCell计算单元, 还要传入上一时h, 以进行前向计算\n",
    "# for xt in xs:\n",
    "#     h = cell(xt, h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "code_folding": [
     0,
     4,
     42,
     61,
     82,
     100
    ]
   },
   "outputs": [],
   "source": [
    "class GeLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1. + torch.tanh(x * 0.7978845608 * (1. + 0.044715 * x * x)))\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, activations=False):\n",
    "        super().__init__()\n",
    "        linear = nn.Linear(in_features, out_features)\n",
    "        nn.init.normal_(linear.weight, std=math.sqrt((2. if activations else 1.) / in_features))\n",
    "        nn.init.zeros_(linear.bias)\n",
    "        modules = [nn.utils.weight_norm(linear)]\n",
    "        if activations:\n",
    "            modules.append(GeLU())\n",
    "        self.model = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class CeLossOut(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        embedding = in_features\n",
    "        self.fc = Linear(in_features, embedding, True)\n",
    "#         self.loss_func = nn.CrossEntropyLoss(weight=torch.tensor([1.,10,50,100,300])).to(args.device)\n",
    "#         self.transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=embedding, nhead=4), \n",
    "#                                                 num_layers=1)\n",
    "        \n",
    "        self.rnn_cell = nn.GRUCell(5, embedding)\n",
    "\n",
    "        self.out = Linear(embedding, 5*args.n_label)\n",
    "        \n",
    "    def loss_func_soft(self, logit, input_dict, i):\n",
    "        logit_softmax = torch.nn.Softmax(1)(logit) \n",
    "        logit_softmax = torch.log(logit_softmax+0.001)\n",
    "        score_arr = logit_softmax * input_dict['24_h_%d'%i]\n",
    "        score_arr = score_arr.mean(1) * input_dict['sample_weight']\n",
    "        loss = -torch.mean(score_arr)\n",
    "        return loss\n",
    "    \n",
    "    def loss_func_hard(self, logit, input_dict, i):\n",
    "        loss_func = nn.CrossEntropyLoss(reduction='none').to(args.device)\n",
    "        loss_arr = loss_func(logit, input_dict['24_h_%d_label'%i])\n",
    "        loss = (loss_arr * input_dict['sample_weight']).mean()\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def forward(self, x, input_dict):\n",
    "#         h = self.fc(x)\n",
    "#         x0 = input_dict['1h_cnt_soft']\n",
    "#         seq_list = []\n",
    "#         for i in range(2,25):\n",
    "#             h = self.rnn_cell(x0, h)\n",
    "#             x0 = self.out(h)\n",
    "#             seq_list.append(x0)\n",
    "\n",
    "#         logit = torch.cat(seq_list, -1)\n",
    "        logit = self.out(x)\n",
    "        loss = None\n",
    "        if input_dict['cal_loss']:\n",
    "            loss = 0\n",
    "            for i in range(2, 25):\n",
    "                idx = i-2\n",
    "                loss += self.loss_func_soft(logit[:, idx*5:idx*5+5], input_dict, i)\n",
    "        return loss, logit\n",
    "\n",
    "class PoissonLossOut(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.out = Linear(in_features, args.n_label)\n",
    "    \n",
    "    def forward(self, x, input_dict):\n",
    "        logit = self.out(x)\n",
    "        loss = None\n",
    "        if input_dict['cal_loss']:\n",
    "            loss_func = nn.PoissonNLLLoss(log_input=True, reduction='none')\n",
    "            max_v = 11\n",
    "            logit[logit>max_v] = max_v\n",
    "            loss_arr = loss_func(logit, input_dict['24h_repost_cnt']-input_dict['1h_repost_cnt'].unsqueeze(-1))\n",
    "#             loss_arr = loss_func(logit, input_dict['24h_repost_residual'])\n",
    "\n",
    "            loss = (loss_arr * input_dict['sample_weight'].unsqueeze(-1)).mean() \n",
    "            loss = loss_arr.mean()\n",
    "        return loss, torch.exp(logit)+input_dict['1h_repost_cnt'].unsqueeze(-1)\n",
    "\n",
    "class MSELossOut(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.out = Linear(in_features, 1)\n",
    "    \n",
    "    def forward(self, x, input_dict):\n",
    "        global forword_cnt_mean, forword_cnt_std\n",
    "        logit = self.out(x)\n",
    "        loss = None\n",
    "        if input_dict['cal_loss']:\n",
    "            norm_target = (input_dict['forword_cnt']-forword_cnt_mean)/forword_cnt_std\n",
    "#             norm_target = torch.log(input_dict['forword_cnt'])\n",
    "            loss_arr = (logit.squeeze(-1)-norm_target)**2\n",
    "#             loss = (loss_arr * input_dict['sample_weight']).mean()\n",
    "            loss = loss_arr.mean()\n",
    "        \n",
    "        logit = logit*forword_cnt_std + forword_cnt_mean\n",
    "#         logit = torch.exp(logit)\n",
    "        logit[logit < 0] = 0\n",
    "        return loss, logit\n",
    "    \n",
    "class TargetLossOut(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.out = Linear(in_features, 5)\n",
    "    \n",
    "    def forward(self, x, input_dict):\n",
    "        global forword_cnt_mean, forword_cnt_std\n",
    "        logit = self.out(x)\n",
    "        loss = None\n",
    "        if input_dict['cal_loss']:\n",
    "            logit_softmax = torch.nn.Softmax(1)(logit) \n",
    "#             logit_softmax = torch.log(logit_softmax+0.001)\n",
    "            score_arr = logit_softmax * torch.tensor([0.00333333,0.03333333,0.16666667,0.33333333,1]).to(logit_softmax.device)\n",
    "            score_arr = score_arr[:, input_dict['label']] * torch.eye(input_dict['label'].shape[0]).to(logit_softmax.device)\n",
    "            loss = -torch.sum(score_arr)/torch.sum(input_dict['sample_weight'])\n",
    "            \n",
    "        return loss, logit         \n",
    "\n",
    "class MLPAttentionPool(nn.Module):\n",
    "    def __init__(self,key_size,units):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(nn.Linear(key_size,units,bias=False),\n",
    "                                  nn.Tanh(),\n",
    "                                  nn.Linear(units,1,bias=False))\n",
    "        \n",
    "    def masked_softmax_1d(self, X, valid_len):\n",
    "        if valid_len is None:\n",
    "            return F.softmax(X,dim=-1), _\n",
    "        else:\n",
    "            shape=X.shape\n",
    "            if valid_len.dim()==1:\n",
    "                valid_len=valid_len.view(-1,1).repeat(1,shape[1])\n",
    "            \n",
    "            mask=(torch.arange(0,X.shape[-1]).to(X.device).repeat(X.shape[0],1)<valid_len).bool()\n",
    "            \n",
    "            X = X.masked_fill_(~mask, -float('inf'))\n",
    "            return F.softmax(X,dim=-1).view(shape), mask\n",
    "\n",
    "    def forward(self, key, valid_len):\n",
    "        scores = self.proj(key).squeeze(-1)\n",
    "        attention_weights, mask = self.masked_softmax_1d(scores,valid_len)\n",
    "        seq_out = attention_weights.unsqueeze(-1) * key\n",
    "        return seq_out.sum(1)\n",
    "    \n",
    "class RepostSetEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        user_id_embed = 10\n",
    "        text_embed = 10\n",
    "        user_dense_embed = 8\n",
    "        self.user_embeding = nn.Embedding(4000, user_id_embed)        \n",
    "        self.attention_pool = MLPAttentionPool(user_id_embed + text_embed + user_dense_embed, 64)\n",
    "        \n",
    "    def forward(self, input_dict):\n",
    "        x_set_wv = input_dict['repost_set_text_wv']\n",
    "        x_set_user_embed = self.user_embeding(input_dict['repost_set_userid'])\n",
    "        x_set_user_dense = input_dict['repost_user_dense']\n",
    "        x = torch.cat([x_set_wv, x_set_user_embed, x_set_user_dense], -1)\n",
    "        return self.attention_pool(x, input_dict['repost_set_len'])\n",
    "    \n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        global continue_feature_list, one_hot_feature_list\n",
    "\n",
    "        in_features = len(continue_feature_list)\n",
    "        bert_encode_feature = 312\n",
    "        bert_encode_feature = 0\n",
    "        text_wv_tfidf_feature = 40\n",
    "        user_id_embed = 10\n",
    "        repost_set_embed = 28\n",
    "#         repost_set_embed = 0\n",
    "        one_hot_feature = len(one_hot_feature_list)\n",
    "        \n",
    "#         global pretrained\n",
    "#         self.albert_weibotext = BertModel.from_pretrained(pretrained).to(args.device)\n",
    "#         self.albert_intro = BertModel.from_pretrained(pretrained).to(args.device)\n",
    "        \n",
    "#         self.transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=bert_encode_feature, nhead=8), \n",
    "#                                                     num_layers=1)\n",
    "\n",
    "        self.user_embeding = nn.Embedding(90, user_id_embed)\n",
    "        \n",
    "        self.repost_set_encoder = RepostSetEncoder().to(args.device)\n",
    "\n",
    "        self.fc = Linear(in_features, args.embedding_size, True)\n",
    "        \n",
    "        self.other_fc = Linear(2*bert_encode_feature + text_wv_tfidf_feature + user_id_embed + repost_set_embed + one_hot_feature,\n",
    "                         args.embedding_size, True)\n",
    "\n",
    "        self.fc_out = Linear(2*args.embedding_size, args.embedding_size, True)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(args.dropout_rate)\n",
    "        \n",
    "        self.out_layer  = CeLossOut(args.embedding_size)\n",
    "        \n",
    "    def forward(self, input_dict):\n",
    "#         x_weibotext = self.albert_weibotext(input_dict['weibo_text_token'])[1]\n",
    "#         x_intro = self.albert_intro(input_dict['intro_text_token'])[1]\n",
    "#         x_seq = self.transformer_encoder(x_seq)\n",
    "#         x_text_out = torch.max(x_seq, 1)[0]\n",
    "#         print(x_bert.shape)\n",
    "        x_user_embed = self.user_embeding(input_dict['user_id_token'])\n",
    "        \n",
    "        x_repost_embeding = self.repost_set_encoder(input_dict)\n",
    "        \n",
    "        x = self.other_fc(torch.cat([input_dict['text_wv_tfidf'], x_user_embed,\n",
    "                       x_repost_embeding, input_dict['one_hot_feature']], 1))\n",
    "        x = torch.cat([x, self.fc(input_dict['x_dense'])], 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return self.out_layer(x, input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_score_cch(predictions, ground_truths):\n",
    "    \n",
    "    predictions, ground_truths = np.array(predictions)-1, np.array(ground_truths)-1\n",
    "    y_pred = predictions\n",
    "    y_true = ground_truths\n",
    "\n",
    "    w=[1,10,50,100,300]\n",
    "    n = len(y_true)\n",
    "    count_r = [0 for i in range(5)]\n",
    "    count = [0 for i in range(5)]\n",
    "    for i in range(n):\n",
    "        count[y_true[i]] += 1\n",
    "        if y_pred[i] == y_true[i]:\n",
    "            count_r[y_pred[i]] += 1\n",
    "    sum1 = sum(w[i]*count_r[i] for i in range(5))\n",
    "    sum2 = sum(w[i]*count[i] for i in range(5))\n",
    "    precision = sum1/sum2\n",
    "    return precision\n",
    "\n",
    "def score_24h(predictions, ground_truths):\n",
    "    return np.abs(predictions-ground_truths).mean(0)\n",
    "    \n",
    "def logit_residual(logits, start_cnt):\n",
    "    logits[:, 0] += start_cnt\n",
    "    for i in range(1, logits.shape[1]):\n",
    "        logits[:, i] += logits[:, i-1]\n",
    "    return logits\n",
    "\n",
    "def score_24h_ce(logits, ground_truths):\n",
    "    ret = []\n",
    "    ground_truths += 1\n",
    "    for i in range(args.n_label):\n",
    "        predictions = np.argmax(logits[:, i*5:i*5+5], 1)+1\n",
    "        ret.append(precision_score_cch(predictions, ground_truths[:, i]))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_nn(weibo_id_list):\n",
    "    train_dataset=WeiboDataset(weibo_id_list)\n",
    "    data_loader = Data.DataLoader(\n",
    "        dataset=train_dataset,      \n",
    "        batch_size=args.batch_size,      \n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers = args.n_worker,\n",
    "    )\n",
    "    \n",
    "    model = DNN().to(args.device)\n",
    "        \n",
    "    no_decay = [\"bias\", \"gamma\",\"beta\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for name, p in model.named_parameters() if 'albert' not in name],\n",
    "            \"lr\": args.lr,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for name, p in model.named_parameters() if 'albert' in name],\n",
    "            \"lr\": args.fine_tune_layer_lr,\n",
    "        },\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr = args.lr, weight_decay = args.weight_decay)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=int(len(weibo_id_list)//(args.batch_size)),\n",
    "        num_training_steps=int(len(weibo_id_list) / args.batch_size * args.epoch)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    for _ in range(args.epoch):\n",
    "        for input_dict in tqdm(data_loader):\n",
    "#             print(word_matrix)\n",
    "            loss, logit = model(input_dict)            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 5)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            if args.debug:\n",
    "                break\n",
    "\n",
    "    return model\n",
    "\n",
    "def forward_nn(model, weibo_id_list):\n",
    "    model.eval()\n",
    "    train_dataset=WeiboDataset(weibo_id_list)\n",
    "    data_loader = Data.DataLoader(\n",
    "        dataset=train_dataset,      \n",
    "        batch_size=args.batch_size,      \n",
    "        shuffle=False,\n",
    "        collate_fn=lambda x:collate_fn(x,True),\n",
    "        num_workers = args.n_worker,\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pre_list = []\n",
    "        for input_dict in tqdm(data_loader):\n",
    "            _, logit = model(input_dict)\n",
    "            pre_list.append(logit.cpu().detach().numpy())\n",
    "    return np.concatenate(pre_list)\n",
    "\n",
    "def cross_validation_nn(train_weibo_id_list, test_weibo_id_list):\n",
    "    global df_repost_24h_origin\n",
    "    n_flod = args.n_flod\n",
    "    folds = KFold(n_splits=n_flod, shuffle=True, random_state=SEED)\n",
    "    train_weibo_id_list = np.array(train_weibo_id_list)\n",
    "    test_weibo_id_list = np.array(test_weibo_id_list)\n",
    "    \n",
    "    \n",
    "    score_train = np.zeros((len(train_weibo_id_list), 5*args.n_label))\n",
    "    score_test = np.zeros((len(test_weibo_id_list), 5*args.n_label))\n",
    "    score_train_train = np.zeros((len(train_weibo_id_list), 5*args.n_label))\n",
    "    \n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train_weibo_id_list, train_weibo_id_list)):\n",
    "        \n",
    "        trn_weibo_id_list = train_weibo_id_list[trn_idx]\n",
    "        val_weibo_id_list = train_weibo_id_list[val_idx]\n",
    "        model = train_nn(trn_weibo_id_list)\n",
    "        \n",
    "        model.eval()\n",
    "        trn_logit = forward_nn(model, trn_weibo_id_list)\n",
    "        val_logit = forward_nn(model, val_weibo_id_list)\n",
    "        \n",
    "#         trn_logit = logit_residual(trn_logit, np.array(df_weibo.loc[trn_weibo_id_list]['repost_weibo_cnt_60_mins']))\n",
    "#         val_logit = logit_residual(val_logit, np.array(df_weibo.loc[val_weibo_id_list]['repost_weibo_cnt_60_mins']))\n",
    "\n",
    "#         print(trn_logit)\n",
    "#         print(pd.Series([count2idx(num)+1 for num in trn_logit[:, 0]]).value_counts())\n",
    "        \n",
    "        ipd.display(pd.DataFrame({\n",
    "            'train': score_24h_ce(trn_logit, np.array(df_repost_24h_label.loc[trn_weibo_id_list]).astype('int')),\n",
    "            'val': score_24h_ce(val_logit, np.array(df_repost_24h_label.loc[val_weibo_id_list]).astype('int')),\n",
    "#             'random':score_24h_ce(np.array(df_repost_24h_origin.loc[val_weibo_id_list].sample(frac=1)), \n",
    "#                                np.array(df_repost_24h_origin.loc[val_weibo_id_list])),\n",
    "        }, index=['%dh'%i for i in range(2, 25)]))\n",
    "        \n",
    "        score_train_train[trn_idx] = trn_logit\n",
    "        score_train[val_idx] = val_logit\n",
    "        \n",
    "        test_logit = forward_nn(model, test_weibo_id_list)\n",
    "#         test_logit = logit_residual(test_logit, np.array(df_weibo.loc[test_weibo_id_list]['repost_weibo_cnt_60_mins']))\n",
    "        score_test += test_logit/n_flod\n",
    "    \n",
    "    \n",
    "    \n",
    "    ipd.display(pd.DataFrame({\n",
    "        'train': score_24h_ce(score_train_train, np.array(df_repost_24h_label.loc[train_weibo_id_list]).astype('int')),\n",
    "        'val': score_24h_ce(score_train, np.array(df_repost_24h_label.loc[train_weibo_id_list]).astype('int')),\n",
    "    }))\n",
    "    return score_train, score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cch/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:437: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int)\n",
      "/home/cch/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:113: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7317fec3aec04c058a5e651fd71e0daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f4a542d0234374b82f65a6584b09a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d96854dd75844b394df8bd5329000b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecda2aa93ff14703abcd725b7f63b002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6d2cfc2cb148d8bb4c7c0be3f8f75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21beea207ce94277a525d1debd54583f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fe9c6902a945559540cfbb4e42ecce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a04b183d2a449cba3cc5bf42043517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ceb0e6252043ec95186bf7831b9577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420bca64d3394fcfb2c7dcbd9c96c640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd1b80461af45948ace6c301cf2896d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e8d79a7ce1497a8e310cfaaa7ecf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2h</th>\n",
       "      <td>0.860680</td>\n",
       "      <td>0.827219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3h</th>\n",
       "      <td>0.849812</td>\n",
       "      <td>0.751524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4h</th>\n",
       "      <td>0.841996</td>\n",
       "      <td>0.735864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5h</th>\n",
       "      <td>0.846016</td>\n",
       "      <td>0.697336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6h</th>\n",
       "      <td>0.853161</td>\n",
       "      <td>0.689350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7h</th>\n",
       "      <td>0.844702</td>\n",
       "      <td>0.651040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8h</th>\n",
       "      <td>0.843930</td>\n",
       "      <td>0.655403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9h</th>\n",
       "      <td>0.849257</td>\n",
       "      <td>0.643209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10h</th>\n",
       "      <td>0.849796</td>\n",
       "      <td>0.645354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11h</th>\n",
       "      <td>0.842023</td>\n",
       "      <td>0.671956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12h</th>\n",
       "      <td>0.838146</td>\n",
       "      <td>0.679289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13h</th>\n",
       "      <td>0.837211</td>\n",
       "      <td>0.680880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14h</th>\n",
       "      <td>0.828957</td>\n",
       "      <td>0.694349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15h</th>\n",
       "      <td>0.828936</td>\n",
       "      <td>0.697977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16h</th>\n",
       "      <td>0.823013</td>\n",
       "      <td>0.704364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17h</th>\n",
       "      <td>0.822540</td>\n",
       "      <td>0.708351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18h</th>\n",
       "      <td>0.822429</td>\n",
       "      <td>0.707174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19h</th>\n",
       "      <td>0.815478</td>\n",
       "      <td>0.705697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20h</th>\n",
       "      <td>0.815350</td>\n",
       "      <td>0.710728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21h</th>\n",
       "      <td>0.814410</td>\n",
       "      <td>0.712350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22h</th>\n",
       "      <td>0.808507</td>\n",
       "      <td>0.712221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23h</th>\n",
       "      <td>0.804736</td>\n",
       "      <td>0.717842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24h</th>\n",
       "      <td>0.803177</td>\n",
       "      <td>0.723098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train       val\n",
       "2h   0.860680  0.827219\n",
       "3h   0.849812  0.751524\n",
       "4h   0.841996  0.735864\n",
       "5h   0.846016  0.697336\n",
       "6h   0.853161  0.689350\n",
       "7h   0.844702  0.651040\n",
       "8h   0.843930  0.655403\n",
       "9h   0.849257  0.643209\n",
       "10h  0.849796  0.645354\n",
       "11h  0.842023  0.671956\n",
       "12h  0.838146  0.679289\n",
       "13h  0.837211  0.680880\n",
       "14h  0.828957  0.694349\n",
       "15h  0.828936  0.697977\n",
       "16h  0.823013  0.704364\n",
       "17h  0.822540  0.708351\n",
       "18h  0.822429  0.707174\n",
       "19h  0.815478  0.705697\n",
       "20h  0.815350  0.710728\n",
       "21h  0.814410  0.712350\n",
       "22h  0.808507  0.712221\n",
       "23h  0.804736  0.717842\n",
       "24h  0.803177  0.723098"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1137941e25ed440cbfe2bc58022f0def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cch/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:113: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8893118ba5344f7e80964a4e007fb808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd9233184f042deb709a38aad683ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cf482f99f947fb99e0599ae3f53707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428142f1520440e79dd58a899869e7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9007cc0d4ee749c9a23ab2ec78a79ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6eec20933945de892dfc2f4068a657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1b6f089d54495b8ffbb270d3ec1e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886ba71171df4e598b443812c0255a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2f56b4d01f4f47913d67af8fbfd5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b5e745bbac4e06a79491cc9eba8230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0511d3c328b74b4d881879777a516ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8387409ff84e4ea0a735ebb3f12e91c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2h</th>\n",
       "      <td>0.873445</td>\n",
       "      <td>0.833216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3h</th>\n",
       "      <td>0.859606</td>\n",
       "      <td>0.787110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4h</th>\n",
       "      <td>0.840132</td>\n",
       "      <td>0.764573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5h</th>\n",
       "      <td>0.842041</td>\n",
       "      <td>0.735137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6h</th>\n",
       "      <td>0.842579</td>\n",
       "      <td>0.740064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7h</th>\n",
       "      <td>0.845003</td>\n",
       "      <td>0.716125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8h</th>\n",
       "      <td>0.840715</td>\n",
       "      <td>0.727753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9h</th>\n",
       "      <td>0.845712</td>\n",
       "      <td>0.725631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10h</th>\n",
       "      <td>0.841960</td>\n",
       "      <td>0.723989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11h</th>\n",
       "      <td>0.847054</td>\n",
       "      <td>0.718424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12h</th>\n",
       "      <td>0.847842</td>\n",
       "      <td>0.716775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13h</th>\n",
       "      <td>0.842185</td>\n",
       "      <td>0.700016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14h</th>\n",
       "      <td>0.838445</td>\n",
       "      <td>0.700070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15h</th>\n",
       "      <td>0.831982</td>\n",
       "      <td>0.683378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16h</th>\n",
       "      <td>0.832986</td>\n",
       "      <td>0.669382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17h</th>\n",
       "      <td>0.825582</td>\n",
       "      <td>0.665318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18h</th>\n",
       "      <td>0.829644</td>\n",
       "      <td>0.662613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19h</th>\n",
       "      <td>0.830153</td>\n",
       "      <td>0.660650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20h</th>\n",
       "      <td>0.826511</td>\n",
       "      <td>0.654928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21h</th>\n",
       "      <td>0.826348</td>\n",
       "      <td>0.651611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22h</th>\n",
       "      <td>0.822532</td>\n",
       "      <td>0.650867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23h</th>\n",
       "      <td>0.817952</td>\n",
       "      <td>0.654093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24h</th>\n",
       "      <td>0.818839</td>\n",
       "      <td>0.662687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train       val\n",
       "2h   0.873445  0.833216\n",
       "3h   0.859606  0.787110\n",
       "4h   0.840132  0.764573\n",
       "5h   0.842041  0.735137\n",
       "6h   0.842579  0.740064\n",
       "7h   0.845003  0.716125\n",
       "8h   0.840715  0.727753\n",
       "9h   0.845712  0.725631\n",
       "10h  0.841960  0.723989\n",
       "11h  0.847054  0.718424\n",
       "12h  0.847842  0.716775\n",
       "13h  0.842185  0.700016\n",
       "14h  0.838445  0.700070\n",
       "15h  0.831982  0.683378\n",
       "16h  0.832986  0.669382\n",
       "17h  0.825582  0.665318\n",
       "18h  0.829644  0.662613\n",
       "19h  0.830153  0.660650\n",
       "20h  0.826511  0.654928\n",
       "21h  0.826348  0.651611\n",
       "22h  0.822532  0.650867\n",
       "23h  0.817952  0.654093\n",
       "24h  0.818839  0.662687"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb378e804974474fb5008c4bbd873625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cch/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:113: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c53a747ff849f280397d83492cc2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a345c6c488754f43b7a13073316b4586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2894a665c54af8b823efca7453bcf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe713055210a4cea89178a0a630acafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b85e98c96042da8387d70dc734a973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513baa077b5c468ab1cd1103610384bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d63760eef1e473eae2a889139f964fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62253d0b4354b5496db4e2242d312d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c904e8633e4c7188c3e557071b8b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd068471504e40598a5f1ae2af20ebdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe43194cccd42b0a90ad1c10a8b5795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357ce4c7e9d44055aa866a5dcbc896b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2h</th>\n",
       "      <td>0.882400</td>\n",
       "      <td>0.826390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3h</th>\n",
       "      <td>0.853488</td>\n",
       "      <td>0.774323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4h</th>\n",
       "      <td>0.842042</td>\n",
       "      <td>0.771760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5h</th>\n",
       "      <td>0.838153</td>\n",
       "      <td>0.746268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6h</th>\n",
       "      <td>0.845899</td>\n",
       "      <td>0.726170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7h</th>\n",
       "      <td>0.850353</td>\n",
       "      <td>0.697484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8h</th>\n",
       "      <td>0.853578</td>\n",
       "      <td>0.669700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9h</th>\n",
       "      <td>0.853551</td>\n",
       "      <td>0.663889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10h</th>\n",
       "      <td>0.850745</td>\n",
       "      <td>0.645284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11h</th>\n",
       "      <td>0.841812</td>\n",
       "      <td>0.639572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12h</th>\n",
       "      <td>0.844265</td>\n",
       "      <td>0.642901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13h</th>\n",
       "      <td>0.842333</td>\n",
       "      <td>0.646675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14h</th>\n",
       "      <td>0.841112</td>\n",
       "      <td>0.633102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15h</th>\n",
       "      <td>0.841318</td>\n",
       "      <td>0.622858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16h</th>\n",
       "      <td>0.834128</td>\n",
       "      <td>0.636155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17h</th>\n",
       "      <td>0.838078</td>\n",
       "      <td>0.637382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18h</th>\n",
       "      <td>0.838143</td>\n",
       "      <td>0.631833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19h</th>\n",
       "      <td>0.836132</td>\n",
       "      <td>0.631215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20h</th>\n",
       "      <td>0.837527</td>\n",
       "      <td>0.622938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21h</th>\n",
       "      <td>0.830019</td>\n",
       "      <td>0.625658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22h</th>\n",
       "      <td>0.826907</td>\n",
       "      <td>0.635159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23h</th>\n",
       "      <td>0.823600</td>\n",
       "      <td>0.630715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24h</th>\n",
       "      <td>0.818665</td>\n",
       "      <td>0.627068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train       val\n",
       "2h   0.882400  0.826390\n",
       "3h   0.853488  0.774323\n",
       "4h   0.842042  0.771760\n",
       "5h   0.838153  0.746268\n",
       "6h   0.845899  0.726170\n",
       "7h   0.850353  0.697484\n",
       "8h   0.853578  0.669700\n",
       "9h   0.853551  0.663889\n",
       "10h  0.850745  0.645284\n",
       "11h  0.841812  0.639572\n",
       "12h  0.844265  0.642901\n",
       "13h  0.842333  0.646675\n",
       "14h  0.841112  0.633102\n",
       "15h  0.841318  0.622858\n",
       "16h  0.834128  0.636155\n",
       "17h  0.838078  0.637382\n",
       "18h  0.838143  0.631833\n",
       "19h  0.836132  0.631215\n",
       "20h  0.837527  0.622938\n",
       "21h  0.830019  0.625658\n",
       "22h  0.826907  0.635159\n",
       "23h  0.823600  0.630715\n",
       "24h  0.818665  0.627068"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4caf7211d9f44ebb4dc4d56db57a92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cch/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:113: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0562d0a5c584713b80e69b5340d2f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3647ad6166648099e8539d8acb1553f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2397723b82594c869bb8d3d1481c2df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24f91a3b1894a80909bebf75d0ddc2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158bfaa081b84fbaa2b42f3086e56815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84fb5cd381094067a663649448527561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f9f7eea6e94d1db1a79f4b317e0a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440b4216f0054ebe91ab6e7b8dbc2cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1dcac15e07402395a580058b846a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652d3d4e85e041e0a6f8a25b714bb68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce5a7292ffb41aea0ffc1aa131640c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c314779573bc4398b153de839dee2297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2h</th>\n",
       "      <td>0.857033</td>\n",
       "      <td>0.829723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3h</th>\n",
       "      <td>0.859677</td>\n",
       "      <td>0.748815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4h</th>\n",
       "      <td>0.840342</td>\n",
       "      <td>0.670905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5h</th>\n",
       "      <td>0.834959</td>\n",
       "      <td>0.649163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6h</th>\n",
       "      <td>0.840250</td>\n",
       "      <td>0.658666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7h</th>\n",
       "      <td>0.834576</td>\n",
       "      <td>0.661993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8h</th>\n",
       "      <td>0.838245</td>\n",
       "      <td>0.662721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9h</th>\n",
       "      <td>0.839521</td>\n",
       "      <td>0.652162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10h</th>\n",
       "      <td>0.840104</td>\n",
       "      <td>0.662566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11h</th>\n",
       "      <td>0.835194</td>\n",
       "      <td>0.650573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12h</th>\n",
       "      <td>0.836467</td>\n",
       "      <td>0.647834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13h</th>\n",
       "      <td>0.843196</td>\n",
       "      <td>0.648413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14h</th>\n",
       "      <td>0.844226</td>\n",
       "      <td>0.638482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15h</th>\n",
       "      <td>0.843804</td>\n",
       "      <td>0.633915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16h</th>\n",
       "      <td>0.836516</td>\n",
       "      <td>0.641126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17h</th>\n",
       "      <td>0.838301</td>\n",
       "      <td>0.650124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18h</th>\n",
       "      <td>0.834974</td>\n",
       "      <td>0.653149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19h</th>\n",
       "      <td>0.836159</td>\n",
       "      <td>0.644905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20h</th>\n",
       "      <td>0.832652</td>\n",
       "      <td>0.647152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21h</th>\n",
       "      <td>0.828504</td>\n",
       "      <td>0.645951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22h</th>\n",
       "      <td>0.827082</td>\n",
       "      <td>0.647779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23h</th>\n",
       "      <td>0.825830</td>\n",
       "      <td>0.641576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24h</th>\n",
       "      <td>0.823312</td>\n",
       "      <td>0.636295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train       val\n",
       "2h   0.857033  0.829723\n",
       "3h   0.859677  0.748815\n",
       "4h   0.840342  0.670905\n",
       "5h   0.834959  0.649163\n",
       "6h   0.840250  0.658666\n",
       "7h   0.834576  0.661993\n",
       "8h   0.838245  0.662721\n",
       "9h   0.839521  0.652162\n",
       "10h  0.840104  0.662566\n",
       "11h  0.835194  0.650573\n",
       "12h  0.836467  0.647834\n",
       "13h  0.843196  0.648413\n",
       "14h  0.844226  0.638482\n",
       "15h  0.843804  0.633915\n",
       "16h  0.836516  0.641126\n",
       "17h  0.838301  0.650124\n",
       "18h  0.834974  0.653149\n",
       "19h  0.836159  0.644905\n",
       "20h  0.832652  0.647152\n",
       "21h  0.828504  0.645951\n",
       "22h  0.827082  0.647779\n",
       "23h  0.825830  0.641576\n",
       "24h  0.823312  0.636295"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e2778ff8f4475d83f8f47b4c5068a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cch/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:113: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dbbb8267c3a43c4bae0c26f9f677336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b22875899954903b9e96af4b6d65b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb2d6577843428f890b4898d013d5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6d3b96dc16469d8830069b481b5c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806e00864ab7408083e2560a43069e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8961852844f74ecfaae35d542df1cab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2a2340c1394c1ba4dd23dcdc91fae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cdc9cfc377425496c365085398a46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85242844aa544c5973a87024be7eb26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08564a93df34f9bbeeecfdc02db59bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca80857927f42f79fbd0ed6d18d8a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d3c3e9d7824d89b75ad22aff22d2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2h</th>\n",
       "      <td>0.872241</td>\n",
       "      <td>0.846738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3h</th>\n",
       "      <td>0.838544</td>\n",
       "      <td>0.825016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4h</th>\n",
       "      <td>0.821091</td>\n",
       "      <td>0.771117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5h</th>\n",
       "      <td>0.829537</td>\n",
       "      <td>0.757197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6h</th>\n",
       "      <td>0.829234</td>\n",
       "      <td>0.754397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7h</th>\n",
       "      <td>0.833763</td>\n",
       "      <td>0.742657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8h</th>\n",
       "      <td>0.832092</td>\n",
       "      <td>0.726578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9h</th>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.721760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10h</th>\n",
       "      <td>0.830431</td>\n",
       "      <td>0.716421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11h</th>\n",
       "      <td>0.829742</td>\n",
       "      <td>0.698567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12h</th>\n",
       "      <td>0.833653</td>\n",
       "      <td>0.678221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13h</th>\n",
       "      <td>0.835418</td>\n",
       "      <td>0.670396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14h</th>\n",
       "      <td>0.836180</td>\n",
       "      <td>0.670771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15h</th>\n",
       "      <td>0.834938</td>\n",
       "      <td>0.664820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16h</th>\n",
       "      <td>0.826825</td>\n",
       "      <td>0.675101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17h</th>\n",
       "      <td>0.825583</td>\n",
       "      <td>0.661827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18h</th>\n",
       "      <td>0.823235</td>\n",
       "      <td>0.658606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19h</th>\n",
       "      <td>0.817334</td>\n",
       "      <td>0.668166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20h</th>\n",
       "      <td>0.817075</td>\n",
       "      <td>0.670544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21h</th>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.659289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22h</th>\n",
       "      <td>0.810537</td>\n",
       "      <td>0.666216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23h</th>\n",
       "      <td>0.803826</td>\n",
       "      <td>0.663693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24h</th>\n",
       "      <td>0.803426</td>\n",
       "      <td>0.661351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train       val\n",
       "2h   0.872241  0.846738\n",
       "3h   0.838544  0.825016\n",
       "4h   0.821091  0.771117\n",
       "5h   0.829537  0.757197\n",
       "6h   0.829234  0.754397\n",
       "7h   0.833763  0.742657\n",
       "8h   0.832092  0.726578\n",
       "9h   0.826835  0.721760\n",
       "10h  0.830431  0.716421\n",
       "11h  0.829742  0.698567\n",
       "12h  0.833653  0.678221\n",
       "13h  0.835418  0.670396\n",
       "14h  0.836180  0.670771\n",
       "15h  0.834938  0.664820\n",
       "16h  0.826825  0.675101\n",
       "17h  0.825583  0.661827\n",
       "18h  0.823235  0.658606\n",
       "19h  0.817334  0.668166\n",
       "20h  0.817075  0.670544\n",
       "21h  0.814237  0.659289\n",
       "22h  0.810537  0.666216\n",
       "23h  0.803826  0.663693\n",
       "24h  0.803426  0.661351"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d21719e0fbe4db8aad0137c2a92ffc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.871755</td>\n",
       "      <td>0.832757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.842234</td>\n",
       "      <td>0.777141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.826161</td>\n",
       "      <td>0.741988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.834478</td>\n",
       "      <td>0.715878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.830985</td>\n",
       "      <td>0.712649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.834227</td>\n",
       "      <td>0.692803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.832933</td>\n",
       "      <td>0.687858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.831221</td>\n",
       "      <td>0.680512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.833187</td>\n",
       "      <td>0.678238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.830843</td>\n",
       "      <td>0.675709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.833939</td>\n",
       "      <td>0.672975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.837152</td>\n",
       "      <td>0.669387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.837043</td>\n",
       "      <td>0.667647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.835215</td>\n",
       "      <td>0.660874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.829501</td>\n",
       "      <td>0.665534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.830048</td>\n",
       "      <td>0.664968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.828110</td>\n",
       "      <td>0.663037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.821109</td>\n",
       "      <td>0.662297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.821653</td>\n",
       "      <td>0.661386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.817148</td>\n",
       "      <td>0.659126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.813158</td>\n",
       "      <td>0.662585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.807535</td>\n",
       "      <td>0.661672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.805821</td>\n",
       "      <td>0.662173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train       val\n",
       "0   0.871755  0.832757\n",
       "1   0.842234  0.777141\n",
       "2   0.826161  0.741988\n",
       "3   0.834478  0.715878\n",
       "4   0.830985  0.712649\n",
       "5   0.834227  0.692803\n",
       "6   0.832933  0.687858\n",
       "7   0.831221  0.680512\n",
       "8   0.833187  0.678238\n",
       "9   0.830843  0.675709\n",
       "10  0.833939  0.672975\n",
       "11  0.837152  0.669387\n",
       "12  0.837043  0.667647\n",
       "13  0.835215  0.660874\n",
       "14  0.829501  0.665534\n",
       "15  0.830048  0.664968\n",
       "16  0.828110  0.663037\n",
       "17  0.821109  0.662297\n",
       "18  0.821653  0.661386\n",
       "19  0.817148  0.659126\n",
       "20  0.813158  0.662585\n",
       "21  0.807535  0.661672\n",
       "22  0.805821  0.662173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "714.5982031822205"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 520\n",
    "ARG = namedtuple('ARG', [\n",
    "    'batch_size',\n",
    "    'epoch',\n",
    "    'lr',\n",
    "    'fine_tune_layer_lr',\n",
    "    'weight_decay',\n",
    "    'dropout_rate',\n",
    "    'n_worker',\n",
    "    'device',\n",
    "    'embedding_size',\n",
    "    'weibo_text_max_length',\n",
    "    'n_flod',\n",
    "    'debug',\n",
    "    'n_label',\n",
    "])\n",
    "\n",
    "args = ARG(\n",
    "    batch_size = 64,\n",
    "    epoch = 5,\n",
    "    lr = 0.01,\n",
    "    fine_tune_layer_lr=2e-5,\n",
    "    weight_decay = 0.01,\n",
    "    dropout_rate = 0.1,\n",
    "    n_worker = 0,\n",
    "    device=torch.device(\"cuda:1\"),\n",
    "#     device=torch.device(\"cpu\"),\n",
    "    embedding_size = 100,\n",
    "    weibo_text_max_length = 500,\n",
    "    n_flod = 5,\n",
    "    debug = False,\n",
    "    n_label = 23\n",
    ")\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "# 设置随机数种子\n",
    "setup_seed(SEED)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "train_weibo_id_list = list(df_weibo.query('type == \"train\"').index)\n",
    "test_weibo_id_list = list(df_weibo.query('type == \"test\"').index)\n",
    "\n",
    "score_train, score_test =\\\n",
    "cross_validation_nn(train_weibo_id_list, test_weibo_id_list)\n",
    "\n",
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_24h_feature_predict = pd.DataFrame(np.concatenate([score_train, score_test], 0),\n",
    "                                      columns = ['24h_%d_ce'%(i) for i in range(score_train.shape[1])],\n",
    "                                      index=train_weibo_id_list+test_weibo_id_list)\n",
    "pickle.dump(df_24h_feature_predict, open('%s/df_24h_feature_predict.pickle'%VAR_PATH, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.674740475156894\n"
     ]
    }
   ],
   "source": [
    "print(precision_score_cch(np.argmax(score_train[:,-5:], 1)+1,\n",
    "                          np.array(df_weibo.loc[train_weibo_id_list]['label']).astype('int')+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>24h_2_cnt</th>\n",
       "      <th>24h_3_cnt</th>\n",
       "      <th>24h_4_cnt</th>\n",
       "      <th>24h_5_cnt</th>\n",
       "      <th>24h_6_cnt</th>\n",
       "      <th>24h_7_cnt</th>\n",
       "      <th>24h_8_cnt</th>\n",
       "      <th>24h_9_cnt</th>\n",
       "      <th>24h_10_cnt</th>\n",
       "      <th>24h_11_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>24h_15_cnt</th>\n",
       "      <th>24h_16_cnt</th>\n",
       "      <th>24h_17_cnt</th>\n",
       "      <th>24h_18_cnt</th>\n",
       "      <th>24h_19_cnt</th>\n",
       "      <th>24h_20_cnt</th>\n",
       "      <th>24h_21_cnt</th>\n",
       "      <th>24h_22_cnt</th>\n",
       "      <th>24h_23_cnt</th>\n",
       "      <th>24h_24_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763ce4f8e9efcdee22c2d6ce213e63b1f537a4f3</th>\n",
       "      <td>13.564613</td>\n",
       "      <td>17.246723</td>\n",
       "      <td>19.855774</td>\n",
       "      <td>21.646484</td>\n",
       "      <td>23.347260</td>\n",
       "      <td>24.956751</td>\n",
       "      <td>26.367662</td>\n",
       "      <td>27.477936</td>\n",
       "      <td>28.860573</td>\n",
       "      <td>29.917555</td>\n",
       "      <td>...</td>\n",
       "      <td>32.665710</td>\n",
       "      <td>32.976688</td>\n",
       "      <td>33.666336</td>\n",
       "      <td>34.407837</td>\n",
       "      <td>34.520889</td>\n",
       "      <td>35.282455</td>\n",
       "      <td>35.874401</td>\n",
       "      <td>36.172356</td>\n",
       "      <td>36.536362</td>\n",
       "      <td>37.350380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42d54a1097102d9a75a511e0f5636a994ff7dd7c</th>\n",
       "      <td>4.681041</td>\n",
       "      <td>5.401617</td>\n",
       "      <td>6.078712</td>\n",
       "      <td>6.533150</td>\n",
       "      <td>6.878187</td>\n",
       "      <td>7.145560</td>\n",
       "      <td>7.275946</td>\n",
       "      <td>7.506338</td>\n",
       "      <td>7.988200</td>\n",
       "      <td>7.812168</td>\n",
       "      <td>...</td>\n",
       "      <td>8.410031</td>\n",
       "      <td>8.473125</td>\n",
       "      <td>8.739178</td>\n",
       "      <td>8.812311</td>\n",
       "      <td>8.738842</td>\n",
       "      <td>8.756796</td>\n",
       "      <td>9.042443</td>\n",
       "      <td>9.183988</td>\n",
       "      <td>9.126014</td>\n",
       "      <td>9.251586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d8941c58c9d2631c20f9c09a9da593b3bbde216</th>\n",
       "      <td>1.231175</td>\n",
       "      <td>1.306143</td>\n",
       "      <td>1.460704</td>\n",
       "      <td>1.489174</td>\n",
       "      <td>1.470732</td>\n",
       "      <td>1.578662</td>\n",
       "      <td>1.579891</td>\n",
       "      <td>1.626033</td>\n",
       "      <td>1.622843</td>\n",
       "      <td>1.695484</td>\n",
       "      <td>...</td>\n",
       "      <td>1.814142</td>\n",
       "      <td>1.769767</td>\n",
       "      <td>1.871040</td>\n",
       "      <td>1.855765</td>\n",
       "      <td>1.844180</td>\n",
       "      <td>1.872044</td>\n",
       "      <td>1.973104</td>\n",
       "      <td>1.887733</td>\n",
       "      <td>1.962945</td>\n",
       "      <td>1.893742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfb9c0df6b005901a35bf88027b0ef55d9000307</th>\n",
       "      <td>1.471867</td>\n",
       "      <td>1.710959</td>\n",
       "      <td>1.897858</td>\n",
       "      <td>2.077141</td>\n",
       "      <td>2.171470</td>\n",
       "      <td>2.288732</td>\n",
       "      <td>2.389746</td>\n",
       "      <td>2.384694</td>\n",
       "      <td>2.481097</td>\n",
       "      <td>2.543777</td>\n",
       "      <td>...</td>\n",
       "      <td>2.772841</td>\n",
       "      <td>2.807849</td>\n",
       "      <td>2.858420</td>\n",
       "      <td>2.986877</td>\n",
       "      <td>2.957128</td>\n",
       "      <td>3.059203</td>\n",
       "      <td>3.056798</td>\n",
       "      <td>3.058477</td>\n",
       "      <td>3.122874</td>\n",
       "      <td>3.211499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ce721859f7ed701a0897897b80d185f69adbc954</th>\n",
       "      <td>15.728475</td>\n",
       "      <td>17.599394</td>\n",
       "      <td>18.838388</td>\n",
       "      <td>19.682812</td>\n",
       "      <td>20.272060</td>\n",
       "      <td>20.860115</td>\n",
       "      <td>21.110653</td>\n",
       "      <td>21.563339</td>\n",
       "      <td>22.031948</td>\n",
       "      <td>22.454010</td>\n",
       "      <td>...</td>\n",
       "      <td>23.839268</td>\n",
       "      <td>24.008007</td>\n",
       "      <td>24.178602</td>\n",
       "      <td>24.432610</td>\n",
       "      <td>24.544291</td>\n",
       "      <td>24.809427</td>\n",
       "      <td>24.919399</td>\n",
       "      <td>25.094673</td>\n",
       "      <td>25.136696</td>\n",
       "      <td>25.405006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359a2b3f0466421bda578e68fdb1ce02d28a5da</th>\n",
       "      <td>0.868205</td>\n",
       "      <td>1.524034</td>\n",
       "      <td>1.706019</td>\n",
       "      <td>2.097161</td>\n",
       "      <td>2.338561</td>\n",
       "      <td>2.599283</td>\n",
       "      <td>2.787515</td>\n",
       "      <td>3.002707</td>\n",
       "      <td>3.070028</td>\n",
       "      <td>3.298299</td>\n",
       "      <td>...</td>\n",
       "      <td>3.804104</td>\n",
       "      <td>3.922921</td>\n",
       "      <td>4.004694</td>\n",
       "      <td>4.155630</td>\n",
       "      <td>4.188793</td>\n",
       "      <td>4.297733</td>\n",
       "      <td>4.435905</td>\n",
       "      <td>4.395230</td>\n",
       "      <td>4.359338</td>\n",
       "      <td>4.679287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e754c308f1a3d968171e1f15a2524ef2b6016a0f</th>\n",
       "      <td>2.969362</td>\n",
       "      <td>3.369297</td>\n",
       "      <td>3.694206</td>\n",
       "      <td>3.861214</td>\n",
       "      <td>4.062732</td>\n",
       "      <td>4.144640</td>\n",
       "      <td>4.363541</td>\n",
       "      <td>4.493313</td>\n",
       "      <td>4.541786</td>\n",
       "      <td>4.568008</td>\n",
       "      <td>...</td>\n",
       "      <td>4.940418</td>\n",
       "      <td>5.006027</td>\n",
       "      <td>5.088579</td>\n",
       "      <td>4.975103</td>\n",
       "      <td>5.199602</td>\n",
       "      <td>5.184316</td>\n",
       "      <td>5.257410</td>\n",
       "      <td>5.310193</td>\n",
       "      <td>5.417529</td>\n",
       "      <td>5.393267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d63e5339dea5a6f6e441691b5ba1adcdca1a49bd</th>\n",
       "      <td>7.091922</td>\n",
       "      <td>8.185369</td>\n",
       "      <td>9.048647</td>\n",
       "      <td>9.556951</td>\n",
       "      <td>10.012577</td>\n",
       "      <td>10.407040</td>\n",
       "      <td>10.919363</td>\n",
       "      <td>11.130489</td>\n",
       "      <td>11.516726</td>\n",
       "      <td>11.841363</td>\n",
       "      <td>...</td>\n",
       "      <td>12.809282</td>\n",
       "      <td>13.106936</td>\n",
       "      <td>13.366754</td>\n",
       "      <td>13.655855</td>\n",
       "      <td>13.637417</td>\n",
       "      <td>13.856207</td>\n",
       "      <td>13.919920</td>\n",
       "      <td>14.214119</td>\n",
       "      <td>14.203831</td>\n",
       "      <td>14.333319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b56faacc0741690d6b50214fd297ea224fb49070</th>\n",
       "      <td>5.749001</td>\n",
       "      <td>10.480298</td>\n",
       "      <td>13.640436</td>\n",
       "      <td>16.218962</td>\n",
       "      <td>20.007818</td>\n",
       "      <td>22.657492</td>\n",
       "      <td>24.345432</td>\n",
       "      <td>26.912754</td>\n",
       "      <td>29.039322</td>\n",
       "      <td>29.475134</td>\n",
       "      <td>...</td>\n",
       "      <td>33.744221</td>\n",
       "      <td>34.641243</td>\n",
       "      <td>35.221287</td>\n",
       "      <td>34.724224</td>\n",
       "      <td>34.611465</td>\n",
       "      <td>37.595409</td>\n",
       "      <td>38.786518</td>\n",
       "      <td>40.192284</td>\n",
       "      <td>39.682659</td>\n",
       "      <td>40.834507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876d0ecb41d06c1bdc50826f72c1939811e4f3c9</th>\n",
       "      <td>93.386551</td>\n",
       "      <td>111.957352</td>\n",
       "      <td>126.331955</td>\n",
       "      <td>137.097290</td>\n",
       "      <td>144.030807</td>\n",
       "      <td>150.745087</td>\n",
       "      <td>156.777679</td>\n",
       "      <td>163.040771</td>\n",
       "      <td>167.161743</td>\n",
       "      <td>171.567383</td>\n",
       "      <td>...</td>\n",
       "      <td>187.762512</td>\n",
       "      <td>190.618256</td>\n",
       "      <td>196.143951</td>\n",
       "      <td>198.527466</td>\n",
       "      <td>199.470032</td>\n",
       "      <td>204.027710</td>\n",
       "      <td>206.457550</td>\n",
       "      <td>207.935196</td>\n",
       "      <td>213.098572</td>\n",
       "      <td>216.085388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          24h_2_cnt   24h_3_cnt   24h_4_cnt  \\\n",
       "763ce4f8e9efcdee22c2d6ce213e63b1f537a4f3  13.564613   17.246723   19.855774   \n",
       "42d54a1097102d9a75a511e0f5636a994ff7dd7c   4.681041    5.401617    6.078712   \n",
       "2d8941c58c9d2631c20f9c09a9da593b3bbde216   1.231175    1.306143    1.460704   \n",
       "dfb9c0df6b005901a35bf88027b0ef55d9000307   1.471867    1.710959    1.897858   \n",
       "ce721859f7ed701a0897897b80d185f69adbc954  15.728475   17.599394   18.838388   \n",
       "...                                             ...         ...         ...   \n",
       "2359a2b3f0466421bda578e68fdb1ce02d28a5da   0.868205    1.524034    1.706019   \n",
       "e754c308f1a3d968171e1f15a2524ef2b6016a0f   2.969362    3.369297    3.694206   \n",
       "d63e5339dea5a6f6e441691b5ba1adcdca1a49bd   7.091922    8.185369    9.048647   \n",
       "b56faacc0741690d6b50214fd297ea224fb49070   5.749001   10.480298   13.640436   \n",
       "876d0ecb41d06c1bdc50826f72c1939811e4f3c9  93.386551  111.957352  126.331955   \n",
       "\n",
       "                                           24h_5_cnt   24h_6_cnt   24h_7_cnt  \\\n",
       "763ce4f8e9efcdee22c2d6ce213e63b1f537a4f3   21.646484   23.347260   24.956751   \n",
       "42d54a1097102d9a75a511e0f5636a994ff7dd7c    6.533150    6.878187    7.145560   \n",
       "2d8941c58c9d2631c20f9c09a9da593b3bbde216    1.489174    1.470732    1.578662   \n",
       "dfb9c0df6b005901a35bf88027b0ef55d9000307    2.077141    2.171470    2.288732   \n",
       "ce721859f7ed701a0897897b80d185f69adbc954   19.682812   20.272060   20.860115   \n",
       "...                                              ...         ...         ...   \n",
       "2359a2b3f0466421bda578e68fdb1ce02d28a5da    2.097161    2.338561    2.599283   \n",
       "e754c308f1a3d968171e1f15a2524ef2b6016a0f    3.861214    4.062732    4.144640   \n",
       "d63e5339dea5a6f6e441691b5ba1adcdca1a49bd    9.556951   10.012577   10.407040   \n",
       "b56faacc0741690d6b50214fd297ea224fb49070   16.218962   20.007818   22.657492   \n",
       "876d0ecb41d06c1bdc50826f72c1939811e4f3c9  137.097290  144.030807  150.745087   \n",
       "\n",
       "                                           24h_8_cnt   24h_9_cnt  24h_10_cnt  \\\n",
       "763ce4f8e9efcdee22c2d6ce213e63b1f537a4f3   26.367662   27.477936   28.860573   \n",
       "42d54a1097102d9a75a511e0f5636a994ff7dd7c    7.275946    7.506338    7.988200   \n",
       "2d8941c58c9d2631c20f9c09a9da593b3bbde216    1.579891    1.626033    1.622843   \n",
       "dfb9c0df6b005901a35bf88027b0ef55d9000307    2.389746    2.384694    2.481097   \n",
       "ce721859f7ed701a0897897b80d185f69adbc954   21.110653   21.563339   22.031948   \n",
       "...                                              ...         ...         ...   \n",
       "2359a2b3f0466421bda578e68fdb1ce02d28a5da    2.787515    3.002707    3.070028   \n",
       "e754c308f1a3d968171e1f15a2524ef2b6016a0f    4.363541    4.493313    4.541786   \n",
       "d63e5339dea5a6f6e441691b5ba1adcdca1a49bd   10.919363   11.130489   11.516726   \n",
       "b56faacc0741690d6b50214fd297ea224fb49070   24.345432   26.912754   29.039322   \n",
       "876d0ecb41d06c1bdc50826f72c1939811e4f3c9  156.777679  163.040771  167.161743   \n",
       "\n",
       "                                          24h_11_cnt  ...  24h_15_cnt  \\\n",
       "763ce4f8e9efcdee22c2d6ce213e63b1f537a4f3   29.917555  ...   32.665710   \n",
       "42d54a1097102d9a75a511e0f5636a994ff7dd7c    7.812168  ...    8.410031   \n",
       "2d8941c58c9d2631c20f9c09a9da593b3bbde216    1.695484  ...    1.814142   \n",
       "dfb9c0df6b005901a35bf88027b0ef55d9000307    2.543777  ...    2.772841   \n",
       "ce721859f7ed701a0897897b80d185f69adbc954   22.454010  ...   23.839268   \n",
       "...                                              ...  ...         ...   \n",
       "2359a2b3f0466421bda578e68fdb1ce02d28a5da    3.298299  ...    3.804104   \n",
       "e754c308f1a3d968171e1f15a2524ef2b6016a0f    4.568008  ...    4.940418   \n",
       "d63e5339dea5a6f6e441691b5ba1adcdca1a49bd   11.841363  ...   12.809282   \n",
       "b56faacc0741690d6b50214fd297ea224fb49070   29.475134  ...   33.744221   \n",
       "876d0ecb41d06c1bdc50826f72c1939811e4f3c9  171.567383  ...  187.762512   \n",
       "\n",
       "                                          24h_16_cnt  24h_17_cnt  24h_18_cnt  \\\n",
       "763ce4f8e9efcdee22c2d6ce213e63b1f537a4f3   32.976688   33.666336   34.407837   \n",
       "42d54a1097102d9a75a511e0f5636a994ff7dd7c    8.473125    8.739178    8.812311   \n",
       "2d8941c58c9d2631c20f9c09a9da593b3bbde216    1.769767    1.871040    1.855765   \n",
       "dfb9c0df6b005901a35bf88027b0ef55d9000307    2.807849    2.858420    2.986877   \n",
       "ce721859f7ed701a0897897b80d185f69adbc954   24.008007   24.178602   24.432610   \n",
       "...                                              ...         ...         ...   \n",
       "2359a2b3f0466421bda578e68fdb1ce02d28a5da    3.922921    4.004694    4.155630   \n",
       "e754c308f1a3d968171e1f15a2524ef2b6016a0f    5.006027    5.088579    4.975103   \n",
       "d63e5339dea5a6f6e441691b5ba1adcdca1a49bd   13.106936   13.366754   13.655855   \n",
       "b56faacc0741690d6b50214fd297ea224fb49070   34.641243   35.221287   34.724224   \n",
       "876d0ecb41d06c1bdc50826f72c1939811e4f3c9  190.618256  196.143951  198.527466   \n",
       "\n",
       "                                          24h_19_cnt  24h_20_cnt  24h_21_cnt  \\\n",
       "763ce4f8e9efcdee22c2d6ce213e63b1f537a4f3   34.520889   35.282455   35.874401   \n",
       "42d54a1097102d9a75a511e0f5636a994ff7dd7c    8.738842    8.756796    9.042443   \n",
       "2d8941c58c9d2631c20f9c09a9da593b3bbde216    1.844180    1.872044    1.973104   \n",
       "dfb9c0df6b005901a35bf88027b0ef55d9000307    2.957128    3.059203    3.056798   \n",
       "ce721859f7ed701a0897897b80d185f69adbc954   24.544291   24.809427   24.919399   \n",
       "...                                              ...         ...         ...   \n",
       "2359a2b3f0466421bda578e68fdb1ce02d28a5da    4.188793    4.297733    4.435905   \n",
       "e754c308f1a3d968171e1f15a2524ef2b6016a0f    5.199602    5.184316    5.257410   \n",
       "d63e5339dea5a6f6e441691b5ba1adcdca1a49bd   13.637417   13.856207   13.919920   \n",
       "b56faacc0741690d6b50214fd297ea224fb49070   34.611465   37.595409   38.786518   \n",
       "876d0ecb41d06c1bdc50826f72c1939811e4f3c9  199.470032  204.027710  206.457550   \n",
       "\n",
       "                                          24h_22_cnt  24h_23_cnt  24h_24_cnt  \n",
       "763ce4f8e9efcdee22c2d6ce213e63b1f537a4f3   36.172356   36.536362   37.350380  \n",
       "42d54a1097102d9a75a511e0f5636a994ff7dd7c    9.183988    9.126014    9.251586  \n",
       "2d8941c58c9d2631c20f9c09a9da593b3bbde216    1.887733    1.962945    1.893742  \n",
       "dfb9c0df6b005901a35bf88027b0ef55d9000307    3.058477    3.122874    3.211499  \n",
       "ce721859f7ed701a0897897b80d185f69adbc954   25.094673   25.136696   25.405006  \n",
       "...                                              ...         ...         ...  \n",
       "2359a2b3f0466421bda578e68fdb1ce02d28a5da    4.395230    4.359338    4.679287  \n",
       "e754c308f1a3d968171e1f15a2524ef2b6016a0f    5.310193    5.417529    5.393267  \n",
       "d63e5339dea5a6f6e441691b5ba1adcdca1a49bd   14.214119   14.203831   14.333319  \n",
       "b56faacc0741690d6b50214fd297ea224fb49070   40.192284   39.682659   40.834507  \n",
       "876d0ecb41d06c1bdc50826f72c1939811e4f3c9  207.935196  213.098572  216.085388  \n",
       "\n",
       "[18000 rows x 23 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_24h_feature_predict.loc[train_weibo_id_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24h_2_reposet_cnt     0\n",
       "24h_3_reposet_cnt     0\n",
       "24h_4_reposet_cnt     1\n",
       "24h_5_reposet_cnt     1\n",
       "24h_6_reposet_cnt     1\n",
       "24h_7_reposet_cnt     1\n",
       "24h_8_reposet_cnt     1\n",
       "24h_9_reposet_cnt     1\n",
       "24h_10_reposet_cnt    1\n",
       "24h_11_reposet_cnt    1\n",
       "24h_12_reposet_cnt    1\n",
       "24h_13_reposet_cnt    1\n",
       "24h_14_reposet_cnt    1\n",
       "24h_15_reposet_cnt    2\n",
       "24h_16_reposet_cnt    2\n",
       "24h_17_reposet_cnt    2\n",
       "24h_18_reposet_cnt    2\n",
       "24h_19_reposet_cnt    2\n",
       "24h_20_reposet_cnt    2\n",
       "24h_21_reposet_cnt    2\n",
       "24h_22_reposet_cnt    2\n",
       "24h_23_reposet_cnt    2\n",
       "24h_24_reposet_cnt    2\n",
       "Name: 2359a2b3f0466421bda578e68fdb1ce02d28a5da, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_repost_24h_origin.loc['2359a2b3f0466421bda578e68fdb1ce02d28a5da']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyr",
   "language": "python",
   "name": "hyr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
